"""
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç–æ–ª–æ–≥–∏–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∞—à–±–æ—Ä–¥–∞ –Ω–∞ Streamlit –¥–ª—è:
- –ó–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (JSON —Ñ–∞–π–ª—ã)
- –ê–≥—Ä–µ–≥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ø–µ–∫—Ç—Ä–∞
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
"""

import sys
from pathlib import Path
from typing import Optional
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import pandas as pd
import numpy as np

try:
    import streamlit as st
    import matplotlib
    import matplotlib.pyplot as plt

    matplotlib.use("Agg")  # –î–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ GUI
except ImportError as e:
    raise ImportError(
        f"–¢—Ä–µ–±—É—é—Ç—Å—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install streamlit matplotlib"
    ) from e

from scale import aggregate, spectral_analysis, domain


def load_predictions_from_upload(uploaded_files) -> dict[str, dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.

    Args:
        uploaded_files: –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (Streamlit UploadedFile)

    Returns:
        –°–ª–æ–≤–∞—Ä—å {image_name: predictions_dict}
    """
    predictions = {}

    for uploaded_file in uploaded_files:
        try:
            data = json.load(uploaded_file)
            image_name = Path(uploaded_file.name).stem
            predictions[image_name] = domain.predictions_from_dict(data)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {uploaded_file.name}: {e}")

    return predictions


def create_experiment_dir(base_dir: Path = Path("experiments")) -> Path:
    """
    –°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

    Args:
        base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

    Returns:
        –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    """
    base_dir = Path(base_dir)
    base_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = base_dir / f"experiment_{timestamp}"
    exp_dir.mkdir(exist_ok=True)

    return exp_dir


def save_experiment(
    exp_dir: Path,
    df: pd.DataFrame,
    analyzer: Optional[spectral_analysis.SpectralAnalyzer] = None,
    metadata: Optional[dict] = None,
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

    Args:
        exp_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        analyzer: –û–±—É—á–µ–Ω–Ω—ã–π SpectralAnalyzer (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    exp_dir = Path(exp_dir)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ DataFrame
    csv_path = exp_dir / "results.csv"
    df.to_csv(csv_path, index=False)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    if analyzer is not None:
        model_path = exp_dir / "spectral_analyzer.pkl"
        analyzer.save(model_path)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    if metadata is None:
        metadata = {}

    metadata["timestamp"] = datetime.now().isoformat()
    metadata["n_samples"] = len(df)

    metadata_path = exp_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)


def render_dashboard():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –¥–∞—à–±–æ—Ä–¥–∞ Streamlit.
    """
    st.set_page_config(
        page_title="–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç–æ–ª–æ–≥–∏–π WSI",
        page_icon="üî¨",
        layout="wide",
    )

    st.title("üî¨ –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç–æ–ª–æ–≥–∏–π Whole Slide Images")
    st.markdown("---")

    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
    with st.sidebar:
        st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")

        uploaded_files = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON —Ñ–∞–π–ª—ã —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏",
            type=["json"],
            accept_multiple_files=True,
        )

        st.markdown("---")

        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

        use_relative_features = st.checkbox(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏", value=True
        )

        use_spectral_analysis = st.checkbox(
            "–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", value=True
        )

        percentile_low = st.slider(
            "–ù–∏–∂–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å", 0.0, 10.0, 1.0, 0.1
        )

        percentile_high = st.slider(
            "–í–µ—Ä—Ö–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å", 90.0, 100.0, 99.0, 0.1
        )

        st.markdown("---")

        st.header("üíæ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã")

        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç"):
            if "df_results" in st.session_state:
                exp_dir = create_experiment_dir()
                save_experiment(
                    exp_dir,
                    st.session_state.df_results,
                    st.session_state.get("analyzer"),
                    {"settings": st.session_state.get("settings", {})},
                )
                st.success(f"–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {exp_dir}")
            else:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    if uploaded_files:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π..."):
            predictions = load_predictions_from_upload(uploaded_files)

        if not predictions:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            return

        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(predictions)} —Ñ–∞–π–ª–æ–≤")

        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        with st.spinner("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö..."):
            rows = []

            for image_name, preds in predictions.items():
                stats = aggregate.aggregate_predictions_from_dict(
                    preds, image_name
                )
                rows.append(stats)

            df = pd.DataFrame(rows)

            if use_relative_features:
                df_features = aggregate.create_relative_features(df)
                df_features = aggregate.select_feature_columns(df_features)
            else:
                df_features = df

        st.session_state.df_results = df_features
        st.session_state.settings = {
            "use_relative_features": use_relative_features,
            "use_spectral_analysis": use_spectral_analysis,
            "percentile_low": percentile_low,
            "percentile_high": percentile_high,
        }

        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        tab1, tab2, tab3, tab4 = st.tabs(
            ["üìä –î–∞–Ω–Ω—ã–µ", "üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è", "üî¨ –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "üìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"]
        )

        with tab1:
            st.header("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            st.dataframe(df_features, use_container_width=True)

            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ CSV
            csv = df_features.to_csv(index=False)
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å CSV",
                data=csv,
                file_name=f"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )

        with tab2:
            st.header("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

            if len(df_features) > 0:
                # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                numeric_cols = df_features.select_dtypes(
                    include=[np.number]
                ).columns.tolist()
                if "image" in numeric_cols:
                    numeric_cols.remove("image")

                selected_features = st.multiselect(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏",
                    numeric_cols,
                    default=numeric_cols[:5] if len(numeric_cols) >= 5 else numeric_cols,
                )

                if selected_features:
                    cols = st.columns(2)

                    for idx, feature in enumerate(selected_features):
                        col = cols[idx % 2]

                        with col:
                            st.subheader(feature)
                            fig, ax = plt.subplots(figsize=(8, 4))
                            ax.hist(
                                df_features[feature].dropna(),
                                bins=20,
                                alpha=0.7,
                                edgecolor="black",
                            )
                            ax.set_xlabel(feature)
                            ax.set_ylabel("Frequency")
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)

        with tab3:
            st.header("–°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")

            if use_spectral_analysis and len(df_features) > 0:
                # –û–±—É—á–µ–Ω–∏–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
                with st.spinner("–û–±—É—á–µ–Ω–∏–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞..."):
                    analyzer = spectral_analysis.SpectralAnalyzer()

                    # PCA
                    analyzer.fit_pca(df_features)

                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ PCA
                    df_pca = analyzer.transform_pca(df_features)

                    # –ê–Ω–∞–ª–∏–∑ —Å–ø–µ–∫—Ç—Ä–∞
                    analyzer.fit_spectrum(
                        df_pca,
                        percentile_low=percentile_low,
                        percentile_high=percentile_high,
                    )

                    # GMM (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    if st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GMM –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π"):
                        analyzer.fit_gmm(df_pca)

                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—É—é —à–∫–∞–ª—É
                    df_spectrum = analyzer.transform_to_spectrum(df_pca)

                st.session_state.analyzer = analyzer

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ø–µ–∫—Ç—Ä–µ
                spectrum_info = analyzer.get_spectrum_info()

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–ß–∏—Å–ª–æ –º–æ–¥", spectrum_info["n_modes"])
                with col2:
                    st.metric(
                        "PC1 –º–µ–¥–∏–∞–Ω–∞",
                        f"{spectrum_info['percentiles']['median']:.2f}",
                    )
                with col3:
                    st.metric(
                        "PC1 std",
                        f"{spectrum_info['percentiles']['std']:.2f}",
                    )

                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–µ–∫—Ç—Ä–∞
                st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–µ–∫—Ç—Ä–∞")

                label_column = None
                if "label" in df_spectrum.columns:
                    label_column = "label"

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
                plot_path = Path("temp_spectrum_plot.png")
                analyzer.visualize_spectrum(
                    df_pca, label_column=label_column, save_path=plot_path
                )

                if plot_path.exists():
                    st.image(str(plot_path))
                    plot_path.unlink()  # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

                # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                display_cols = ["image", "PC1", "PC1_spectrum"]
                if "PC1_mode" in df_spectrum.columns:
                    display_cols.append("PC1_mode")

                st.dataframe(
                    df_spectrum[display_cols].sort_values(
                        by="PC1_spectrum", ascending=False
                    ),
                    use_container_width=True,
                )

                # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                st.subheader("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (PC1 loadings)")
                feature_importance = analyzer.get_feature_importance()

                fig, ax = plt.subplots(figsize=(10, 6))
                top_n = st.slider("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø N –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", 5, 30, 15)
                top_features = feature_importance.head(top_n)

                ax.barh(
                    range(len(top_features)),
                    top_features.values,
                    align="center",
                )
                ax.set_yticks(range(len(top_features)))
                ax.set_yticklabels(top_features.index)
                ax.set_xlabel("Loading value")
                ax.set_title("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ PC1")
                ax.grid(True, alpha=0.3, axis="x")
                st.pyplot(fig)

            else:
                st.info("–í–∫–ª—é—á–∏—Ç–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")

        with tab4:
            st.header("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

            if len(df_features) > 0:
                numeric_cols = df_features.select_dtypes(
                    include=[np.number]
                ).columns.tolist()

                if numeric_cols:
                    st.subheader("–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                    st.dataframe(
                        df_features[numeric_cols].describe(),
                        use_container_width=True,
                    )

                    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                    if len(numeric_cols) > 1:
                        st.subheader("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")
                        corr_matrix = df_features[numeric_cols].corr()

                        fig, ax = plt.subplots(figsize=(12, 10))
                        im = ax.imshow(corr_matrix, cmap="coolwarm", aspect="auto")
                        ax.set_xticks(range(len(corr_matrix.columns)))
                        ax.set_yticks(range(len(corr_matrix.columns)))
                        ax.set_xticklabels(corr_matrix.columns, rotation=45, ha="right")
                        ax.set_yticklabels(corr_matrix.columns)
                        plt.colorbar(im, ax=ax)
                        st.pyplot(fig)

    else:
        st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON —Ñ–∞–π–ª—ã —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏")


if __name__ == "__main__":
    render_dashboard()

