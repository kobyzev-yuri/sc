# Работа с экспериментами

## Что такое эксперимент?

Эксперимент — это сохраненный набор результатов анализа WSI (Whole Slide Images), включающий:
- Результаты вычисления шкалы патологии (DataFrame с оценками)
- Обученные модели (SpectralAnalyzer, PCAScorer)
- Метаданные (настройки, время создания, количество образцов)
- Конфигурацию признаков (выбранные признаки для анализа)

---

## Структура экспериментов

### Тип 1: Эксперименты подбора признаков (feature_selection_*)

Создаются при автоматизированном подборе признаков.

**Обязательные файлы:**
- `best_features_YYYYMMDD_HHMMSS.json` - конфигурация лучшего метода с метриками
- `feature_selection_results_YYYYMMDD_HHMMSS.csv` - таблица сравнения всех методов

**Рекомендуемые файлы:**
- `aggregated_data_YYYYMMDD_HHMMSS.csv` - агрегированные данные (абсолютные признаки)
- `relative_features_YYYYMMDD_HHMMSS.csv` - относительные признаки
- `all_features_YYYYMMDD_HHMMSS.csv` - все доступные признаки

**Пример структуры:**
```
experiments/feature_selection_quick/
├── best_features_20251116_143516.json
├── feature_selection_results_20251116_143516.csv
├── aggregated_data_20251116_143516.csv
├── relative_features_20251116_143516.csv
└── all_features_20251116_143516.csv
```

### Тип 2: Эксперименты из dashboard (experiment_*)

Создаются при сохранении результатов через веб-интерфейс.

**Обязательные файлы:**
- `results.csv` - результаты анализа (PC1, PC1_norm, PC1_spectrum и т.д.)
- `metadata.json` - метаданные эксперимента

**Опциональные файлы:**
- `spectral_analyzer.pkl` - обученная модель (для инференса)
- `best_features_YYYYMMDD_HHMMSS.json` - конфигурация признаков

**Пример структуры:**
```
experiments/experiment_20251108_220146/
├── results.csv
├── metadata.json
├── spectral_analyzer.pkl
└── best_features_20251108_220146.json
```

---

## Формат файлов

### best_features_*.json

Конфигурация лучшего метода подбора признаков:

```json
{
  "method": "forward",
  "selected_features": [
    "Dysplasia_mean_relative_area",
    "Mild_relative_area",
    ...
  ],
  "metrics": {
    "score": 3.0783,
    "separation": 6.7901,
    "mean_pc1_norm_mod": 0.6802,
    "explained_variance": 0.5274
  },
  "timestamp": "20251116_143516"
}
```

### metadata.json

Метаданные эксперимента:

```json
{
  "timestamp": "2025-11-08T22:01:46.914744",
  "n_samples": 10,
  "settings": {
    "use_relative_features": true,
    "use_spectral_analysis": true,
    "percentile_low": 1.0,
    "percentile_high": 99.0
  },
  "source_experiment": "feature_selection_quick"
}
```

### results.csv

Результаты анализа. Колонки:
- `image` - имя изображения
- `PC1` - первая главная компонента
- `PC1_norm` - нормализованная оценка (0-1)
- `PC1_spectrum` - спектральная оценка (если использовался SpectralAnalyzer)
- `PC1_mode` - классификация по модам (если использовался SpectralAnalyzer)

---

## Сохранение экспериментов

### Через Dashboard

1. Загрузите данные в dashboard
2. Выберите признаки и запустите анализ
3. Нажмите кнопку **"Сохранить эксперимент"** в боковой панели

Эксперимент будет сохранен с автоматически сгенерированным именем `experiment_YYYYMMDD_HHMMSS`.

### Программно

```python
from pathlib import Path
from scale.dashboard import create_experiment_dir, save_experiment
from scale import spectral_analysis
import pandas as pd

# Создание директории эксперимента
exp_dir = create_experiment_dir()

# Подготовка данных
df_results = pd.DataFrame(...)  # Ваши результаты
analyzer = spectral_analysis.SpectralAnalyzer()
analyzer.fit_pca(df_features)
# ... обучение модели ...

# Сохранение эксперимента
save_experiment(
    exp_dir=exp_dir,
    df=df_results,
    analyzer=analyzer,  # опционально
    metadata={"description": "Мой эксперимент", "version": "1.0"},
    selected_features=feature_list  # опционально
)
```

---

## Загрузка экспериментов

### Загрузка метаданных и результатов

```python
import json
import pandas as pd
from pathlib import Path

exp_dir = Path("experiments/experiment_20251108_220146")

# Загрузка метаданных
with open(exp_dir / "metadata.json", "r") as f:
    metadata = json.load(f)
print(f"Эксперимент создан: {metadata['timestamp']}")

# Загрузка результатов
df_results = pd.read_csv(exp_dir / "results.csv")
print(df_results.head())
```

### Загрузка обученной модели

```python
from scale import spectral_analysis

exp_dir = Path("experiments/experiment_20251108_220146")

# Загрузка SpectralAnalyzer
analyzer = spectral_analysis.SpectralAnalyzer()
analyzer.load(exp_dir / "spectral_analyzer.pkl")

# Применение к новым данным
df_new_results = analyzer.transform_pca(df_new_features)
```

### Загрузка конфигурации признаков

```python
import json
from pathlib import Path

exp_dir = Path("experiments/feature_selection_quick")
best_features_file = list(exp_dir.glob("best_features_*.json"))[0]

with open(best_features_file, "r") as f:
    config = json.load(f)

selected_features = config["selected_features"]
print(f"Выбрано признаков: {len(selected_features)}")
print(f"Score: {config['metrics']['score']:.4f}")
```

---

## Управление экспериментами в Dashboard

### Безопасная работа

**Важно:** Dashboard НЕ перезаписывает исходные экспериментальные конфиги!

### Как это работает:

1. **Выбор эксперимента:**
   - В dashboard можно выбрать эксперимент из списка
   - Признаки загружаются из эксперимента
   - Исходный эксперимент НЕ изменяется

2. **Ручной выбор признаков:**
   - Можно вручную изменять признаки в dashboard
   - Изменения сохраняются в `scale/cfg/feature_selection_config_relative.json`
   - Исходный эксперимент остается нетронутым

3. **Отслеживание источника:**
   - Dashboard отслеживает, из какого эксперимента загружены признаки
   - При сохранении сохраняется информация об исходном эксперименте

### Структура файлов

```
experiments/
└── feature_selection_quick/
    └── best_features_*.json          ← Исходный эксперимент (НЕ изменяется)

scale/
└── cfg/
    └── feature_selection_config_relative.json  ← Текущая конфигурация dashboard
                                                  (может быть изменена пользователем)
```

---

## Сравнение экспериментов

### Сравнение двух экспериментов

```python
import pandas as pd
from pathlib import Path

# Загрузка результатов двух экспериментов
exp1_dir = Path("experiments/experiment_20251108_220146")
exp2_dir = Path("experiments/experiment_20251115_103022")

df1 = pd.read_csv(exp1_dir / "results.csv")
df2 = pd.read_csv(exp2_dir / "results.csv")

# Объединение для сравнения
comparison = pd.merge(
    df1[["image", "PC1_norm"]].rename(columns={"PC1_norm": "exp1_score"}),
    df2[["image", "PC1_norm"]].rename(columns={"PC1_norm": "exp2_score"}),
    on="image",
    how="outer"
)

# Вычисление различий
comparison["difference"] = comparison["exp1_score"] - comparison["exp2_score"]
print(comparison.describe())
```

### Сравнение нескольких экспериментов

```python
import pandas as pd
from pathlib import Path
import glob

# Поиск всех экспериментов
experiments = sorted(Path("experiments").glob("experiment_*"))

# Загрузка результатов всех экспериментов
all_results = {}
for exp_dir in experiments:
    if (exp_dir / "results.csv").exists():
        df = pd.read_csv(exp_dir / "results.csv")
        exp_name = exp_dir.name
        all_results[exp_name] = df[["image", "PC1_norm"]].rename(
            columns={"PC1_norm": exp_name}
        )

# Объединение всех результатов
comparison = None
for exp_name, df in all_results.items():
    if comparison is None:
        comparison = df
    else:
        comparison = pd.merge(comparison, df, on="image", how="outer")

print(comparison.head())
```

---

## Рекомендации

1. **Именование:** Используйте описательные имена для экспериментов сравнения
2. **Метаданные:** Всегда добавляйте метаданные с описанием эксперимента и параметрами
3. **Версионирование:** Сохраняйте версии моделей и параметров в метаданных
4. **Резервное копирование:** Регулярно делайте резервные копии важных экспериментов
5. **Документация:** Ведите README в директории экспериментов с описанием целей и результатов
6. **Сохраняйте данные:** Включайте `aggregated_data`, `relative_features` и `all_features` при экспорте
7. **Сохраняйте модели:** `spectral_analyzer.pkl` необходим для инференса новых данных

---

## FAQ

### Q: Изменятся ли исходные эксперименты при работе в dashboard?

**A:** Нет! Исходные эксперименты (`experiments/*/best_features_*.json`) **НЕ изменяются**. Изменения сохраняются только в `scale/cfg/feature_selection_config_relative.json`.

### Q: Можно ли вернуться к исходной конфигурации эксперимента?

**A:** Да! Можно восстановить исходную конфигурацию в dashboard или экспортировать эксперимент заново.

### Q: Что происходит при сохранении конфигурации в dashboard?

**A:** Изменения сохраняются в `scale/cfg/feature_selection_config_relative.json`, сохраняется информация об исходном эксперименте, исходный эксперимент НЕ изменяется.

### Q: Какой минимальный набор файлов нужен для работы в dashboard?

**A:** Достаточно `best_features_*.json` для загрузки конфигурации признаков и одного из файлов данных (`aggregated_data_*.csv`, `relative_features_*.csv` или `all_features_*.csv`) для загрузки данных.

