# Формулы для Score и Mutual Information Score

## 1. Score (Комплексная метрика качества)

### Формула

```
score = 0.4 × separation + 0.3 × mean_pc1_norm_mod + 0.3 × explained_variance
```

### Компоненты формулы

#### 1.1. Separation (Разделение классов)

```
separation = mean_pc1_mod - mean_pc1_normal
```

где:
- `mean_pc1_mod` = среднее значение PC1 для патологических образцов (mod)
- `mean_pc1_normal` = среднее значение PC1 для нормальных образцов (normal)

**Вычисление:**
```python
# После обучения PCA на выбранных признаках
X_pca = pca.fit_transform(X_scaled)  # X_scaled - стандартизированные признаки

pc1_mod = X_pca[mod_mask, 0]         # PC1 для патологических образцов
pc1_normal = X_pca[normal_mask, 0]    # PC1 для нормальных образцов

mean_pc1_mod = np.mean(pc1_mod)
mean_pc1_normal = np.mean(pc1_normal)
separation = mean_pc1_mod - mean_pc1_normal
```

**Интерпретация:**
- Положительное значение → патологические образцы имеют более высокие значения PC1
- Чем больше, тем лучше разделение
- Целевое значение: > 6.0 (хорошо), > 7.0 (отлично)

#### 1.2. mean_pc1_norm_mod (Нормализованная позиция mod образцов)

```
mean_pc1_norm_mod = mean((pc1_mod - pc1_min) / (pc1_max - pc1_min))
```

где:
- `pc1_mod` = значения PC1 для патологических образцов
- `pc1_min` = минимальное значение PC1 среди всех образцов
- `pc1_max` = максимальное значение PC1 среди всех образцов

**Вычисление:**
```python
pc1_min = X_pca.min()  # Минимум по всем образцам
pc1_max = X_pca.max()  # Максимум по всем образцам

if pc1_max > pc1_min:
    pc1_norm_mod = (pc1_mod - pc1_min) / (pc1_max - pc1_min)
    mean_pc1_norm_mod = np.mean(pc1_norm_mod)
else:
    mean_pc1_norm_mod = 0.5  # Если все значения одинаковы
```

**Интерпретация:**
- Диапазон: [0, 1]
- 0.0 → патологические образцы имеют минимальные значения PC1 (плохо)
- 1.0 → патологические образцы имеют максимальные значения PC1 (отлично)
- Целевое значение: > 0.70 (хорошо), > 0.85 (отлично)

#### 1.3. explained_variance (Объясненная дисперсия)

```
explained_variance = λ₁ / Σλᵢ
```

где:
- `λ₁` = собственное значение первой главной компоненты (PC1)
- `Σλᵢ` = сумма всех собственных значений

**Вычисление:**
```python
pca = PCA(n_components=1)
X_pca = pca.fit_transform(X_scaled)
explained_variance = pca.explained_variance_ratio_[0]
```

**Интерпретация:**
- Диапазон: [0, 1]
- Показывает, какая доля общей вариации данных объясняется PC1
- 0.3 → PC1 объясняет 30% вариации
- 0.5 → PC1 объясняет 50% вариации
- Целевое значение: > 0.30 (хорошо), > 0.50 (отлично)

### Полная формула Score

```
score = 0.4 × (mean_pc1_mod - mean_pc1_normal) 
      + 0.3 × mean((pc1_mod - pc1_min) / (pc1_max - pc1_min))
      + 0.3 × (λ₁ / Σλᵢ)
```

### Веса компонентов

- **40%** - separation (разделение классов) - самый важный фактор
- **30%** - mean_pc1_norm_mod (позиция патологических образцов)
- **30%** - explained_variance (качество PCA)

### Пример вычисления

Для Forward Selection с 24 признаками:
- separation = 7.3632
- mean_pc1_norm_mod = 0.7067
- explained_variance = 0.3570

```
score = 0.4 × 7.3632 + 0.3 × 0.7067 + 0.3 × 0.3570
     = 2.9453 + 0.2120 + 0.1071
     = 3.2644
```

### Диапазоны значений

- **Плохо:** score < 2.0
- **Удовлетворительно:** 2.0 ≤ score < 3.0
- **Хорошо:** 3.0 ≤ score < 3.5
- **Отлично:** score ≥ 3.5

---

## 2. Mutual Information Score (MI Score)

### Математическая формула

```
I(X; Y) = Σₓ Σᵧ p(x, y) × log(p(x, y) / (p(x) × p(y)))
```

где:
- `X` = признак (feature)
- `Y` = метка класса (mod/normal)
- `p(x, y)` = совместная вероятность P(X=x, Y=y)
- `p(x)` = маргинальная вероятность P(X=x)
- `p(y)` = маргинальная вероятность P(Y=y)

### Альтернативная формула через энтропию

```
I(X; Y) = H(X) + H(Y) - H(X, Y)
```

где:
- `H(X)` = энтропия признака X
- `H(Y)` = энтропия метки класса Y
- `H(X, Y)` = совместная энтропия X и Y

### Энтропия (формула Шеннона)

```
H(X) = -Σₓ p(x) × log₂(p(x))
```

### Вычисление в sklearn

В нашем коде используется `mutual_info_classif` из sklearn:

```python
from sklearn.feature_selection import mutual_info_classif

# Создаем метки классов
y = (df['sample_type'] == 'mod').astype(int).values  # 1 для mod, 0 для normal

# Вычисляем MI для всех признаков
X = df[candidate_features].fillna(0).values
mi_scores = mutual_info_classif(X, y, random_state=42)
```

### Как работает mutual_info_classif

1. **Дискретизация** (если признак непрерывный):
   - Разбивает значения признака на интервалы (bins)
   - По умолчанию использует квантили

2. **Вычисление вероятностей:**
   - `p(x)` = частота значения x в признаке
   - `p(y)` = частота класса y (mod или normal)
   - `p(x, y)` = совместная частота (x, y)

3. **Вычисление MI:**
   ```
   I(X; Y) = Σₓ Σᵧ count(x, y) / N × log₂((count(x, y) / N) / ((count(x) / N) × (count(y) / N)))
   ```
   где N = общее число образцов

### Пример вычисления MI

**Данные:**
- Признак: `Neutrophils_relative_count`
- Значения: [0.1, 0.2, 0.3, 0.4, 0.5, ...]
- Классы: [mod, mod, normal, mod, normal, ...]

**Шаг 1: Дискретизация**
```
Интервал 1: [0.0, 0.2] → 3 образца (2 mod, 1 normal)
Интервал 2: [0.2, 0.4] → 5 образцов (3 mod, 2 normal)
Интервал 3: [0.4, 0.6] → 4 образца (1 mod, 3 normal)
...
```

**Шаг 2: Вычисление вероятностей**
```
p(x₁) = 3/12 = 0.25
p(y=mod) = 6/12 = 0.5
p(y=normal) = 6/12 = 0.5
p(x₁, mod) = 2/12 = 0.167
p(x₁, normal) = 1/12 = 0.083
```

**Шаг 3: Вычисление MI**
```
I(X; Y) = p(x₁, mod) × log₂(p(x₁, mod) / (p(x₁) × p(mod)))
        + p(x₁, normal) × log₂(p(x₁, normal) / (p(x₁) × p(normal)))
        + ... (для всех интервалов)
```

### Интерпретация MI Score

- **MI = 0** → признак и класс независимы (признак не информативен)
- **MI > 0** → признак содержит информацию о классе
- **Чем больше MI, тем больше информации** признак содержит о классе

### Диапазоны значений MI

Для нашей задачи (бинарная классификация mod/normal):
- **Низкий MI:** 0.0 - 0.2 (мало информации)
- **Средний MI:** 0.2 - 0.4 (умеренная информация)
- **Высокий MI:** 0.4 - 0.6 (много информации)
- **Очень высокий MI:** > 0.6 (очень информативный признак)

### Примеры MI scores из наших результатов

Из эксперимента `feature_selection_all_methods`:
- `Mild_relative_area`: MI ≈ 0.45-0.52 (высокий)
- `Neutrophils_relative_count`: MI ≈ 0.48-0.52 (высокий)
- `Moderate_relative_count`: MI ≈ 0.35-0.40 (средний)
- `Paneth_relative_count`: MI ≈ 0.28-0.32 (средний)

### Почему MI не всегда коррелирует с Score?

**MI Score:**
- Оценивает **индивидуальную** информативность признака
- Не учитывает **взаимодействие** с другими признаками
- Не учитывает, как признак работает в **PCA**

**Score:**
- Оценивает **комбинацию** признаков
- Учитывает **взаимодействие** через PCA
- Оптимизирует **целевую метрику** (separation, mod позиция)

**Пример:**
- Признак A: MI = 0.5, но в PCA дает плохое разделение → низкий score
- Признак B: MI = 0.4, но в PCA хорошо работает с другими → высокий score

---

## Сравнение формул

| Метрика | Формула | Оптимизирует | Учитывает взаимодействие |
|---------|---------|--------------|-------------------------|
| **Score** | `0.4×separation + 0.3×mod_norm + 0.3×variance` | Целевую метрику | ✅ Да (через PCA) |
| **MI Score** | `ΣₓΣᵧ p(x,y)×log(p(x,y)/(p(x)×p(y)))` | Информативность | ❌ Нет (индивидуально) |

---

## Рекомендации

### Когда использовать Score?

✅ Для **финального отбора** признаков  
✅ Когда важна **точность** разделения классов  
✅ Когда признаки могут **взаимодействовать** друг с другом  

### Когда использовать MI Score?

✅ Для **быстрой предварительной фильтрации**  
✅ Когда нужно **быстро отсеять** неинформативные признаки  
✅ Как **первый этап** перед Forward Selection  

### Комбинированный подход

1. **Этап 1:** MI Score → отфильтровать до топ-20-25 признаков
2. **Этап 2:** Forward Selection с Score → выбрать финальные 15-20 признаков

Это сочетает скорость MI и точность Score!

