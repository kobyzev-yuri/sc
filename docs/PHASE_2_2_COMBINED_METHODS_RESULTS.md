# Фаза 2.2: Результаты комбинированных методов отбора признаков

**Дата:** 2025-11-16  
**Статус:** ✅ Завершено

## Цель фазы

Протестировать комбинированные подходы для улучшения Forward Selection:
- MI → Forward Selection (двухэтапный отбор)
- Forward → Backward (последовательное применение)
- Forward ∩ Backward (пересечение признаков)
- Forward ∪ Backward (объединение признаков)

## Результаты экспериментов

### Сравнительная таблица

| Метод | Score | Separation | Mod (норм.) | Объясн. дисперсия | Признаков | Изменение Score |
|-------|-------|------------|-------------|-------------------|-----------|-----------------|
| **forward (базовый)** | **3.2644** | 7.3632 | 0.7067 | 0.3570 | 24 | - |
| forward_backward_union | 3.2635 | **7.4130** | 0.6936 | 0.3007 | 30 | -0.0009 (-0.03%) |
| forward_backward_intersection | 3.2609 | 7.3571 | 0.6911 | 0.3690 | 24 | -0.0035 (-0.11%) |
| forward_then_backward | 3.2609 | 7.3571 | 0.6911 | 0.3690 | 24 | -0.0035 (-0.11%) |
| mi_then_forward_k25 | 3.1752 | 7.1160 | **0.7113** | 0.3847 | 22 | -0.0892 (-2.73%) |

### Детальный анализ методов

#### 1. Forward ∪ Backward (объединение)

**Параметры:**
- Forward: min_improvement=0.01 → 24 признака
- Backward: min_improvement=0.01 → 30 признаков
- Объединение: 30 признаков

**Результаты:**
- ✅ **Лучшее Separation:** 7.4130 (+0.68% vs базовый)
- ✅ Score практически идентичен базовому (-0.03%)
- ⚠️ Использует больше признаков (30 vs 24)

**Вывод:** Хороший вариант, если приоритет - максимальное разделение классов, а не компактность модели.

#### 2. Forward ∩ Backward (пересечение)

**Параметры:**
- Forward: min_improvement=0.01 → 24 признака
- Backward: min_improvement=0.01 → 30 признаков
- Пересечение: 24 признака (все из Forward)

**Результаты:**
- Score: 3.2609 (-0.11% vs базовый)
- Separation: 7.3571 (идентично базовому)
- Признаков: 24 (идентично базовому)

**Вывод:** Подтверждает стабильность базового Forward - все его признаки важны и стабильно выбираются обоими методами.

#### 3. Forward → Backward

**Параметры:**
- Forward: max_features=30, min_improvement=0.01 → 24 признака
- Backward: min_improvement=0.01 → не удалил ни одного признака

**Результаты:**
- Score: 3.2609 (-0.11% vs базовый)
- Separation: 7.3571 (идентично базовому)
- Признаков: 24 (идентично базовому)

**Вывод:** Подтверждает оптимальность набора из 24 признаков - нельзя улучшить удалением признаков.

#### 4. MI → Forward Selection

**Параметры:**
- MI: k=25 → отфильтровано до 25 признаков
- Forward: min_improvement=0.01 → 22 признака

**Результаты:**
- ❌ Score хуже на 2.73% (3.1752 vs 3.2644)
- ❌ Separation хуже на 3.36% (7.1160 vs 7.3632)
- ✅ Лучше позиция mod образцов (0.7113 vs 0.7067)
- ✅ Меньше признаков (22 vs 24)

**Вывод:** Не улучшает базовый Forward. MI фильтрация убирает важные признаки, что приводит к потере качества.

## Ключевые выводы

### ✅ Что подтверждено:

1. **Forward Selection оптимален:**
   - Все комбинированные методы дают результаты близкие или хуже базового Forward
   - Разница в Score < 0.11% (в пределах погрешности)
   - Forward → Backward не смог улучшить результат удалением признаков
   - Forward ∩ Backward подтверждает важность всех 24 признаков

2. **Forward ∪ Backward дает лучшее Separation:**
   - Score: 3.2635 (практически идентично базовому)
   - Separation: 7.4130 (лучше на 0.68%)
   - Но использует больше признаков (30 vs 24)

### ❌ Что не работает:

1. **MI → Forward Selection:**
   - Хуже базового Forward на 2.73%
   - MI фильтрация убирает важные признаки
   - Не рекомендуется для финального отбора

2. **Комбинированные методы не улучшают базовый Forward:**
   - Все дают результаты близкие или хуже
   - Базовый Forward уже оптимален для текущего train set

## Рекомендации для production

### Вариант 1: Базовый Forward Selection (рекомендуется)
- **Score:** 3.2644
- **Separation:** 7.3632
- **Признаков:** 24
- **Преимущества:** Оптимальный баланс качества и компактности

### Вариант 2: Forward ∪ Backward (альтернатива)
- **Score:** 3.2635
- **Separation:** 7.4130 (лучше!)
- **Признаков:** 30
- **Преимущества:** Максимальное разделение классов
- **Недостатки:** Больше признаков

## Следующие шаги

### Ближайшие задачи:

1. **Расширение train set:**
   - При добавлении новых данных для обучения
   - Если это улучшит score → накапливать статистику
   - Сравнивать результаты на разных train sets

2. **Расширение наборов признаков:**
   - Параллельно с расширением данных
   - Новые типы признаков для шкалы
   - Тестировать на расширенном train set

### Будущие эксперименты (отложены):

1. **Оптимизация параметров Forward Selection:**
   - Вариации min_improvement (0.001, 0.005, 0.01, 0.02, 0.05)
   - Вариации max_features (15, 20, 24, 25, 30)
   - ⏸️ Отложено до расширения train set

2. **Анализ типов признаков:**
   - Только count признаки
   - Только area признаки
   - Комбинации типов
   - ⏸️ Отложено до расширения train set

## Статус экспериментов

- ✅ Фаза 1: Базовое сравнение методов - завершена
- ✅ Фаза 2.2: Комбинированные методы - завершена
- ⏸️ Фаза 2.1: Оптимизация параметров - отложена
- ⏸️ Фаза 3: Анализ типов признаков - отложена

## Файлы результатов

- `experiments/fs_mi_then_forward_k25/` - MI → Forward
- `experiments/fs_forward_then_backward/` - Forward → Backward
- `experiments/fs_forward_backward_intersection/` - Forward ∩ Backward
- `experiments/fs_forward_backward_union/` - Forward ∪ Backward
- `experiments/COMBINED_METHODS_ANALYSIS.md` - Детальный анализ

## Заключение

Комбинированные методы не улучшили базовый Forward Selection. Это подтверждает оптимальность текущего подхода для существующего train set. 

**Следующий этап:** Расширение train set и наборов признаков с накоплением статистики для сравнения результатов.

