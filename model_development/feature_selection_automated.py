"""
–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —à–∫–∞–ª—ã –Ω–∞ –±–∞–∑–µ PCA.

–¶–µ–ª—å: –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –æ–±—Ä–∞–∑—Ü—ã —Å –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º–∏ (mod)
–ø–æ–ª—É—á–∞—é—Ç –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è PC1 (–±–ª–∏–∂–µ –∫ 1 –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —à–∫–∞–ª–µ).
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Callable, Union
from itertools import combinations
import json
from datetime import datetime

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import (
    SelectKBest,
    f_classif,
    mutual_info_classif,
    RFE,
    RFECV,
)
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ scale –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, str(Path(__file__).parent.parent))

from scale import aggregate, pca_scoring
from model_development import feature_selection_export


# –ö—ç—à –¥–ª—è —Ä—É—á–Ω—ã—Ö –º–µ—Ç–æ–∫ (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑)
_manual_labels_cache = None

def _load_manual_labels() -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä—É—á–Ω—ã–µ –º–µ—Ç–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    global _manual_labels_cache
    if _manual_labels_cache is not None:
        return _manual_labels_cache
    
    _manual_labels_cache = {}
    manual_labels_file = Path(__file__).parent.parent / "scale" / "cfg" / "manual_sample_labels.json"
    
    if manual_labels_file.exists():
        try:
            with open(manual_labels_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                _manual_labels_cache = config.get("manual_labels", {})
        except Exception as e:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—É—á–Ω—ã–µ –º–µ—Ç–∫–∏ –∏–∑ {manual_labels_file}: {e}")
            _manual_labels_cache = {}
    
    return _manual_labels_cache


def identify_sample_type(image_name: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ–±—Ä–∞–∑—Ü–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.
    
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä—É—á–Ω—ã–µ –º–µ—Ç–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞,
    –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.
    
    Args:
        image_name: –ò–º—è —Ñ–∞–π–ª–∞/–æ–±—Ä–∞–∑—Ü–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .json –∏–ª–∏ –±–µ–∑)
        
    Returns:
        'mod' –¥–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤, 'normal' –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö, 'unknown' –¥–ª—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö
    """
    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .json –µ—Å–ª–∏ –µ—Å—Ç—å
    image_name_clean = image_name.replace('.json', '')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä—É—á–Ω—ã–µ –º–µ—Ç–∫–∏
    manual_labels = _load_manual_labels()
    if image_name_clean in manual_labels:
        return manual_labels[image_name_clean]
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    image_name_lower = image_name.lower()
    if 'mod' in image_name_lower or 'ibd' in image_name_lower:
        return 'mod'
    elif 'wnl' in image_name_lower:
        return 'normal'
    else:
        return 'unknown'


def evaluate_feature_set(
    df: pd.DataFrame,
    feature_columns: List[str],
    mod_samples: List[str],
    normal_samples: List[str],
) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è mod –∏ normal –æ–±—Ä–∞–∑—Ü–æ–≤.
    
    Args:
        df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        feature_columns: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        mod_samples: –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω mod –æ–±—Ä–∞–∑—Ü–æ–≤
        normal_samples: –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω normal –æ–±—Ä–∞–∑—Ü–æ–≤
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    mod_mask = df['image'].isin(mod_samples)
    normal_mask = df['image'].isin(normal_samples)
    
    if mod_mask.sum() == 0 or normal_mask.sum() == 0:
        return {
            'score': -np.inf,
            'mean_pc1_mod': -np.inf,
            'mean_pc1_normal': np.inf,
            'separation': -np.inf,
            'explained_variance': 0.0,
        }
    
    # –ö–†–ò–¢–ò–ß–ù–û: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ PCA
    # –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ PCA –∏–∑-–∑–∞ —á–∏—Å–ª–µ–Ω–Ω–æ–π –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –ø–æ—Ä—è–¥–æ–∫ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    sorted_feature_columns = sorted(feature_columns)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
    missing_features = [f for f in sorted_feature_columns if f not in df.columns]
    if missing_features:
        raise ValueError(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –¥–∞–Ω–Ω—ã—Ö: {missing_features}")
    
    # –û–±—É—á–∞–µ–º PCA
    # –ö–†–ò–¢–ò–ß–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º sorted_feature_columns –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    X = df[sorted_feature_columns].fillna(0).values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # –ö–†–ò–¢–ò–ß–ù–û: –î–æ–±–∞–≤–ª—è–µ–º random_state –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    # PCA –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑-–∑–∞ —á–∏—Å–ª–µ–Ω–Ω–æ–π –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    # random_state –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    pca = PCA(n_components=1, random_state=42)
    X_pca = pca.fit_transform(X_scaled)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    pc1_mod = X_pca[mod_mask, 0]
    pc1_normal = X_pca[normal_mask, 0]
    
    mean_pc1_mod = np.mean(pc1_mod)
    mean_pc1_normal = np.mean(pc1_normal)
    separation = mean_pc1_mod - mean_pc1_normal
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º PC1 –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–∑–∏—Ü–∏–∏ mod –æ–±—Ä–∞–∑—Ü–æ–≤
    pc1_min = X_pca.min()
    pc1_max = X_pca.max()
    if pc1_max > pc1_min:
        pc1_norm_mod = (pc1_mod - pc1_min) / (pc1_max - pc1_min)
        mean_pc1_norm_mod = np.mean(pc1_norm_mod)
    else:
        mean_pc1_norm_mod = 0.5
    
    explained_variance = pca.explained_variance_ratio_[0]
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏ –ø–æ–∑–∏—Ü–∏—é mod –æ–±—Ä–∞–∑—Ü–æ–≤
    score = (
        0.4 * separation +  # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
        0.3 * mean_pc1_norm_mod +  # –ü–æ–∑–∏—Ü–∏—è mod –æ–±—Ä–∞–∑—Ü–æ–≤ (–±–ª–∏–∂–µ –∫ 1)
        0.3 * explained_variance  # –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
    )
    
    return {
        'score': score,
        'mean_pc1_mod': mean_pc1_mod,
        'mean_pc1_normal': mean_pc1_normal,
        'mean_pc1_norm_mod': mean_pc1_norm_mod,
        'separation': separation,
        'explained_variance': explained_variance,
    }


class FeatureSelector:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    
    def __init__(self, df: pd.DataFrame):
        """
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –∫–æ–ª–æ–Ω–∫–æ–π 'image'
        """
        self.df = df.copy()
        self.df['sample_type'] = self.df['image'].apply(identify_sample_type)
        
        mod_mask = self.df['sample_type'] == 'mod'
        normal_mask = self.df['sample_type'] == 'normal'
        
        self.mod_samples = self.df[mod_mask]['image'].tolist()
        self.normal_samples = self.df[normal_mask]['image'].tolist()
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: mod={len(self.mod_samples)}, normal={len(self.normal_samples)}")
    
    def method_1_forward_selection(
        self,
        candidate_features: List[str],
        max_features: Optional[int] = None,
        min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 1: Forward Selection (–∂–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º).
        
        –ù–∞—á–∏–Ω–∞–µ—Ç —Å –ø—É—Å—Ç–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏,
        –∫–æ—Ç–æ—Ä—ã–µ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—é—Ç —Ü–µ–ª–µ–≤—É—é –º–µ—Ç—Ä–∏–∫—É.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
            min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        selected = []
        best_score = -np.inf
        best_metrics = {}
        
        remaining = candidate_features.copy()
        
        if max_features is None:
            max_features = len(candidate_features)
        
        print(f"\n=== Forward Selection ===")
        print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(candidate_features)}")
        
        while len(selected) < max_features and remaining:
            best_feature = None
            best_new_score = best_score
            
            for feature in remaining:
                test_features = selected + [feature]
                metrics = evaluate_feature_set(
                    self.df, test_features, self.mod_samples, self.normal_samples
                )
                
                if metrics['score'] > best_new_score:
                    best_new_score = metrics['score']
                    best_feature = feature
                    best_metrics = metrics
            
            if best_feature is None or (best_new_score - best_score) < min_improvement:
                break
            
            selected.append(best_feature)
            remaining.remove(best_feature)
            best_score = best_new_score
            
            print(f"–®–∞–≥ {len(selected)}: –¥–æ–±–∞–≤–ª–µ–Ω '{best_feature}', score={best_score:.4f}, "
                  f"separation={best_metrics['separation']:.4f}, "
                  f"mod_norm={best_metrics['mean_pc1_norm_mod']:.4f}")
        
        return selected, best_metrics
    
    def method_2_backward_elimination(
        self,
        candidate_features: List[str],
        min_features: int = 1,
        min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 2: Backward Elimination.
        
        –ù–∞—á–∏–Ω–∞–µ—Ç —Å–æ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç –Ω–∞–∏–º–µ–Ω–µ–µ –≤–∞–∂–Ω—ã–µ.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_features: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        selected = candidate_features.copy()
        
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        metrics = evaluate_feature_set(
            self.df, selected, self.mod_samples, self.normal_samples
        )
        best_score = metrics['score']
        best_metrics = metrics
        
        print(f"\n=== Backward Elimination ===")
        print(f"–ù–∞—á–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected)}")
        print(f"–ù–∞—á–∞–ª—å–Ω—ã–π score: {best_score:.4f}")
        
        while len(selected) > min_features:
            worst_feature = None
            best_new_score = best_score
            
            for feature in selected:
                test_features = [f for f in selected if f != feature]
                test_metrics = evaluate_feature_set(
                    self.df, test_features, self.mod_samples, self.normal_samples
                )
                
                if test_metrics['score'] > best_new_score:
                    best_new_score = test_metrics['score']
                    worst_feature = feature
            
            if worst_feature is None or (best_new_score - best_score) < min_improvement:
                break
            
            selected.remove(worst_feature)
            best_score = best_new_score
            best_metrics = evaluate_feature_set(
                self.df, selected, self.mod_samples, self.normal_samples
            )
            
            print(f"–®–∞–≥: —É–¥–∞–ª–µ–Ω '{worst_feature}', –æ—Å—Ç–∞–ª–æ—Å—å {len(selected)}, "
                  f"score={best_score:.4f}, "
                  f"separation={best_metrics['separation']:.4f}, "
                  f"mod_norm={best_metrics['mean_pc1_norm_mod']:.4f}")
        
        return selected, best_metrics
    
    def method_3_positive_loadings_filter(
        self,
        candidate_features: List[str],
        min_loading: float = 0.05,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º loadings PC1.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ loadings –≤ PC1,
        —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –ø–∞—Ç–æ–ª–æ–≥–∏–µ–π.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_loading: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π loading –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Positive Loadings Filter ===")
        
        # –û–±—É—á–∞–µ–º PCA –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        pca = PCA(n_components=1)
        pca.fit(X_scaled)
        
        # –ü–æ–ª—É—á–∞–µ–º loadings
        loadings = pd.Series(pca.components_[0], index=candidate_features)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ loadings
        positive_features = [
            feat for feat, loading in loadings.items()
            if loading > min_loading
        ]
        
        print(f"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö loadings (> {min_loading}): {len(positive_features)} –∏–∑ {len(candidate_features)}")
        
        if not positive_features:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ loadings!")
            positive_features = candidate_features
        
        metrics = evaluate_feature_set(
            self.df, positive_features, self.mod_samples, self.normal_samples
        )
        
        return positive_features, metrics
    
    def method_4_mutual_information(
        self,
        candidate_features: List[str],
        k: Optional[int] = None,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 4: –û—Ç–±–æ—Ä –ø–æ Mutual Information.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∑–∞–∏–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            k: –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞ (None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Mutual Information Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –í—ã—á–∏—Å–ª—è–µ–º mutual information
        X = self.df[candidate_features].fillna(0).values
        mi_scores = mutual_info_classif(X, y, random_state=42)
        
        mi_df = pd.DataFrame({
            'feature': candidate_features,
            'mi_score': mi_scores
        }).sort_values('mi_score', ascending=False)
        
        print(f"–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI:")
        print(mi_df.head(10).to_string(index=False))
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-k –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if k is None:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å MI > –º–µ–¥–∏–∞–Ω—ã
            threshold = mi_df['mi_score'].median()
            selected_features = mi_df[mi_df['mi_score'] > threshold]['feature'].tolist()
        else:
            selected_features = mi_df.head(k)['feature'].tolist()
        
        print(f"–û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_5_lasso_selection(
        self,
        candidate_features: List[str],
        cv: int = 5,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 5: L1-regularization (LASSO) –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LASSO –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            cv: –ß–∏—Å–ª–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== LASSO Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # LASSO —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        lasso = LassoCV(cv=cv, random_state=42, max_iter=2000)
        lasso.fit(X_scaled, y)
        
        # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
        selected_features = [
            candidate_features[i] for i in range(len(candidate_features))
            if abs(lasso.coef_[i]) > 1e-6
        ]
        
        print(f"LASSO –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {len(candidate_features)}")
        print(f"Alpha (—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è): {lasso.alpha_:.6f}")
        
        if not selected_features:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: LASSO –Ω–µ –≤—ã–±—Ä–∞–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞!")
            selected_features = candidate_features
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_6_rfe_selection(
        self,
        candidate_features: List[str],
        n_features: Optional[int] = None,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 6: Recursive Feature Elimination (RFE).
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç RFE –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            n_features: –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞ (None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ RFECV)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== RFE Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        estimator = RandomForestClassifier(n_estimators=100, random_state=42)
        
        if n_features is None:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —á–µ—Ä–µ–∑ RFECV
            rfecv = RFECV(estimator=estimator, step=1, cv=5, scoring='roc_auc')
            rfecv.fit(X_scaled, y)
            selected_features = [
                candidate_features[i] for i in range(len(candidate_features))
                if rfecv.support_[i]
            ]
            print(f"RFECV –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        else:
            # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            rfe = RFE(estimator=estimator, n_features_to_select=n_features)
            rfe.fit(X_scaled, y)
            selected_features = [
                candidate_features[i] for i in range(len(candidate_features))
                if rfe.support_[i]
            ]
            print(f"RFE –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_7_brute_force_combinations(
        self,
        candidate_features: List[str],
        max_features: int = 5,
        max_combinations: int = 1000,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 7: –ü–µ—Ä–µ–±–æ—Ä –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è –º–∞–ª–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤).
        
        –ü–µ—Ä–µ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            max_combinations: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Brute Force Combinations ===")
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        best_features = None
        best_score = -np.inf
        best_metrics = {}
        
        total_combinations = sum(
            len(list(combinations(candidate_features, k)))
            for k in range(1, min(max_features + 1, len(candidate_features) + 1))
        )
        
        if total_combinations > max_combinations:
            print(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π ({total_combinations}), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {max_combinations}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            import random
            combinations_to_test = []
            for k in range(1, min(max_features + 1, len(candidate_features) + 1)):
                for _ in range(max_combinations // max_features):
                    combo = random.sample(candidate_features, min(k, len(candidate_features)))
                    combinations_to_test.append(combo)
        else:
            # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            combinations_to_test = []
            for k in range(1, min(max_features + 1, len(candidate_features) + 1)):
                combinations_to_test.extend(combinations(candidate_features, k))
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º {len(combinations_to_test)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π...")
        
        for i, combo in enumerate(combinations_to_test):
            if i % 100 == 0:
                print(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ {i}/{len(combinations_to_test)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π...")
            
            metrics = evaluate_feature_set(
                self.df, list(combo), self.mod_samples, self.normal_samples
            )
            
            if metrics['score'] > best_score:
                best_score = metrics['score']
                best_features = list(combo)
                best_metrics = metrics
        
        print(f"–õ—É—á—à–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: {len(best_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, score={best_score:.4f}")
        
        return best_features, best_metrics
    
    def method_combined_mi_then_forward(
        self,
        candidate_features: List[str],
        mi_k: int = 25,
        forward_min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Mutual Information ‚Üí Forward Selection.
        
        –≠—Ç–∞–ø 1: MI —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥–æ —Ç–æ–ø-k –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        –≠—Ç–∞–ø 2: Forward Selection –≤—ã–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            mi_k: –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞ —á–µ—Ä–µ–∑ MI
            forward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Forward Selection
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: MI ‚Üí Forward Selection ===")
        print(f"–≠—Ç–∞–ø 1: Mutual Information —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥–æ {mi_k} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –≠—Ç–∞–ø 1: MI —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        mi_features, mi_metrics = self.method_4_mutual_information(
            candidate_features,
            k=mi_k
        )
        
        print(f"‚úì –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –¥–æ {len(mi_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ MI")
        print(f"–≠—Ç–∞–ø 2: Forward Selection –Ω–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö...")
        
        # –≠—Ç–∞–ø 2: Forward Selection –Ω–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        final_features, final_metrics = self.method_1_forward_selection(
            mi_features,
            min_improvement=forward_min_improvement
        )
        
        print(f"‚úì –§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä: {len(final_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return final_features, final_metrics
    
    def method_combined_forward_then_backward(
        self,
        candidate_features: List[str],
        forward_max_features: int = 30,
        forward_min_improvement: float = 0.01,
        backward_min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward Selection ‚Üí Backward Elimination.
        
        –≠—Ç–∞–ø 1: Forward Selection –¥–æ max_features –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        –≠—Ç–∞–ø 2: Backward Elimination –∏–∑ Forward –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            forward_max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è Forward
            forward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Forward
            backward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Backward
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward ‚Üí Backward ===")
        print(f"–≠—Ç–∞–ø 1: Forward Selection –¥–æ {forward_max_features} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –≠—Ç–∞–ø 1: Forward Selection
        forward_features, forward_metrics = self.method_1_forward_selection(
            candidate_features,
            max_features=forward_max_features,
            min_improvement=forward_min_improvement
        )
        
        print(f"‚úì Forward Selection –≤—ã–±—Ä–∞–ª {len(forward_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"–≠—Ç–∞–ø 2: Backward Elimination –∏–∑ Forward –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –≠—Ç–∞–ø 2: Backward Elimination
        final_features, final_metrics = self.method_2_backward_elimination(
            forward_features,
            min_improvement=backward_min_improvement
        )
        
        print(f"‚úì –§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä: {len(final_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        return final_features, final_metrics
    
    def method_combined_forward_backward_intersection(
        self,
        candidate_features: List[str],
        forward_min_improvement: float = 0.01,
        backward_min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward + Backward (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ).
        
        –ù–∞—Ö–æ–¥–∏—Ç –æ–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –æ–±–æ–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            forward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Forward
            backward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Backward
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward ‚à© Backward (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ) ===")
        print(f"–≠—Ç–∞–ø 1: Forward Selection...")
        
        # Forward Selection
        forward_features, _ = self.method_1_forward_selection(
            candidate_features,
            min_improvement=forward_min_improvement
        )
        
        print(f"‚úì Forward Selection –≤—ã–±—Ä–∞–ª {len(forward_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"–≠—Ç–∞–ø 2: Backward Elimination...")
        
        # Backward Elimination
        backward_features, _ = self.method_2_backward_elimination(
            candidate_features,
            min_improvement=backward_min_improvement
        )
        
        print(f"‚úì Backward Elimination –≤—ã–±—Ä–∞–ª {len(backward_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        intersection_features = list(set(forward_features) & set(backward_features))
        
        print(f"‚úì –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: {len(intersection_features)} –æ–±—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        metrics = evaluate_feature_set(
            self.df, intersection_features, self.mod_samples, self.normal_samples
        )
        
        return intersection_features, metrics
    
    def method_combined_forward_backward_union(
        self,
        candidate_features: List[str],
        forward_min_improvement: float = 0.01,
        backward_min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward + Backward (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ).
        
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –æ–±–æ–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            forward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Forward
            backward_min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è Backward
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥: Forward ‚à™ Backward (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ) ===")
        print(f"–≠—Ç–∞–ø 1: Forward Selection...")
        
        # Forward Selection
        forward_features, _ = self.method_1_forward_selection(
            candidate_features,
            min_improvement=forward_min_improvement
        )
        
        print(f"‚úì Forward Selection –≤—ã–±—Ä–∞–ª {len(forward_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"–≠—Ç–∞–ø 2: Backward Elimination...")
        
        # Backward Elimination
        backward_features, _ = self.method_2_backward_elimination(
            candidate_features,
            min_improvement=backward_min_improvement
        )
        
        print(f"‚úì Backward Elimination –≤—ã–±—Ä–∞–ª {len(backward_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        union_features = list(set(forward_features) | set(backward_features))
        
        print(f"‚úì –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ: {len(union_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        metrics = evaluate_feature_set(
            self.df, union_features, self.mod_samples, self.normal_samples
        )
        
        return union_features, metrics
    
    def compare_all_methods(
        self,
        candidate_features: List[str],
        methods: Optional[List[str]] = None,
        method_params: Optional[Dict[str, Dict]] = None,
    ) -> pd.DataFrame:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (None = –≤—Å–µ –º–µ—Ç–æ–¥—ã)
            method_params: –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –º–µ—Ç–æ–¥–æ–≤ {method_name: {param: value}}
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if methods is None:
            methods = [
                'forward',
                'backward',
                'positive_loadings',
                'mutual_information',
                'lasso',
                'rfe',
            ]
        
        if method_params is None:
            method_params = {}
        
        results = []
        
        for method_name in methods:
            print(f"\n{'='*60}")
            print(f"–ú–µ—Ç–æ–¥: {method_name}")
            print(f"{'='*60}")
            
            try:
                params = method_params.get(method_name, {})
                
                if method_name == 'forward':
                    features, metrics = self.method_1_forward_selection(
                        candidate_features,
                        min_improvement=params.get('min_improvement', 0.01)
                    )
                elif method_name == 'backward':
                    features, metrics = self.method_2_backward_elimination(
                        candidate_features,
                        min_improvement=params.get('min_improvement', 0.01)
                    )
                elif method_name == 'positive_loadings':
                    features, metrics = self.method_3_positive_loadings_filter(
                        candidate_features,
                        min_loading=params.get('min_loading', 0.05)
                    )
                elif method_name == 'mutual_information':
                    features, metrics = self.method_4_mutual_information(
                        candidate_features,
                        k=params.get('k', None)
                    )
                elif method_name == 'lasso':
                    features, metrics = self.method_5_lasso_selection(
                        candidate_features,
                        cv=params.get('cv', 5)
                    )
                elif method_name == 'rfe':
                    features, metrics = self.method_6_rfe_selection(
                        candidate_features,
                        n_features=params.get('n_features', None)
                    )
                else:
                    continue
                
                results.append({
                    'method': method_name,
                    'n_features': len(features),
                    'features': features,
                    **metrics
                })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method_name}: {e}")
                continue
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('score', ascending=False)
        
        return results_df


def run_feature_selection_analysis(
    predictions_dir: Union[str, Path],
    output_dir: Optional[Union[str, Path]] = None,
    methods: Optional[List[str]] = None,
    train_set: Optional[str] = None,
    aggregation_version: Optional[str] = None,
    use_all_relative_features: bool = False,
) -> pd.DataFrame:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        predictions_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å JSON —Ñ–∞–π–ª–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (None = –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å)
        methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
    Returns:
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
    """
    print("="*60)
    print("–ê–í–¢–û–ú–ê–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–û–î–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í –î–õ–Ø –ú–ï–î–ò–¶–ò–ù–°–ö–û–ô –®–ö–ê–õ–´")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = aggregate.load_predictions_batch(predictions_dir)
    # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–∑—Ü—ã –ø–æ –∏–º–µ–Ω–∏
    if "image" in df.columns:
        df = df.sort_values("image").reset_index(drop=True)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(df)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n2. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df_features = aggregate.create_relative_features(df)
    print(f"   –í—Å–µ–≥–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features.columns) - 1}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    if use_all_relative_features:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Å–µ—Ö –ø–∞—Ç–æ–ª–æ–≥–∏–π
        df_all = df_features
        candidate_features = [c for c in df_all.columns if c != 'image']
        print("   –†–µ–∂–∏–º: –ò–°–ü–û–õ–¨–ó–£–ï–ú –í–°–ï –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–±–µ–∑ —Ä—É—á–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∫–ª–∞—Å—Å–æ–≤)")
    else:
        # –°—Ç–∞—Ä—ã–π –ø–æ–¥—Ö–æ–¥: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º
        df_all = aggregate.select_all_feature_columns(df_features)
        candidate_features = [c for c in df_all.columns if c != "image"]
        print(f"   –ö–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–æ–≤): {len(candidate_features)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    print("\n3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    selector = FeatureSelector(df_all)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    print("\n4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    results_df = selector.compare_all_methods(candidate_features, methods=methods)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "="*60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø –ú–ï–¢–û–î–û–í")
    print("="*60)
    print(results_df[['method', 'n_features', 'score', 'separation', 
                      'mean_pc1_norm_mod', 'explained_variance']].to_string(index=False))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if output_dir is not None:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print("\n5. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        saved_files = feature_selection_export.export_complete_results(
            results_df=results_df,
            output_dir=output_dir,
            use_relative_features=True,
            auto_export_to_dashboard=False,  # –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            df_aggregated=df,  # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
            df_features=df_features,  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ –∫–ª–∞—Å—Å—ã)
            df_all_features=df_all,  # –ü—Ä–∏–∑–Ω–∞–∫–∏, —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ –∞–Ω–∞–ª–∏–∑–µ
        )
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ —Ç—Ä–µ–∫–µ—Ä–µ –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
        try:
            from model_development.experiment_tracker import register_experiment_from_directory
            register_experiment_from_directory(
                experiment_dir=output_dir,
                train_set=train_set or str(predictions_dir),
                aggregation_version=aggregation_version or "current",
            )
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ —Ç—Ä–µ–∫–µ—Ä–µ: {e}")
        
        print("\n" + "="*60)
        print("–≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù")
        print("="*60)
        print(f"‚úì –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç: {saved_files.get('medical_report', 'N/A')}")
        print(f"‚úì CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {saved_files.get('csv', 'N/A')}")
        print(f"‚úì JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {saved_files.get('json', 'N/A')}")
        if saved_files.get('aggregated_data'):
            print(f"‚úì –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {saved_files.get('aggregated_data', 'N/A')}")
        if saved_files.get('relative_features'):
            print(f"‚úì –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('relative_features', 'N/A')}")
        if saved_files.get('all_features'):
            print(f"‚úì –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('all_features', 'N/A')}")
        print(f"\nüí° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dashboard –ù–ï –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)")
        print(f"   –ß—Ç–æ–±—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ dashboard, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"   python3 -m scale.feature_selection_versioning_cli export {output_dir.name}")
    
    return results_df


if __name__ == "__main__":
    import sys
    
    predictions_dir = sys.argv[1] if len(sys.argv) > 1 else "results/predictions"
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "experiments/feature_selection"
    
    results = run_feature_selection_analysis(predictions_dir, output_dir)

