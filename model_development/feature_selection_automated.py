"""
–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —à–∫–∞–ª—ã –Ω–∞ –±–∞–∑–µ PCA.

–¶–µ–ª—å: –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –æ–±—Ä–∞–∑—Ü—ã —Å –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è–º–∏ (mod)
–ø–æ–ª—É—á–∞—é—Ç –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è PC1 (–±–ª–∏–∂–µ –∫ 1 –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —à–∫–∞–ª–µ).
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Callable, Union
from itertools import combinations
import json
from datetime import datetime

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import (
    SelectKBest,
    f_classif,
    mutual_info_classif,
    RFE,
    RFECV,
)
from sklearn.linear_model import LogisticRegression, LassoCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ scale –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, str(Path(__file__).parent.parent))

from scale import aggregate, pca_scoring
from model_development import feature_selection_export


def identify_sample_type(image_name: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ–±—Ä–∞–∑—Ü–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.
    
    Args:
        image_name: –ò–º—è —Ñ–∞–π–ª–∞/–æ–±—Ä–∞–∑—Ü–∞
        
    Returns:
        'mod' –¥–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤, 'normal' –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö
    """
    image_name_lower = image_name.lower()
    if 'mod' in image_name_lower or 'ibd' in image_name_lower:
        return 'mod'
    elif 'wnl' in image_name_lower:
        return 'normal'
    else:
        return 'unknown'


def evaluate_feature_set(
    df: pd.DataFrame,
    feature_columns: List[str],
    mod_samples: List[str],
    normal_samples: List[str],
) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è mod –∏ normal –æ–±—Ä–∞–∑—Ü–æ–≤.
    
    Args:
        df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        feature_columns: –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        mod_samples: –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω mod –æ–±—Ä–∞–∑—Ü–æ–≤
        normal_samples: –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω normal –æ–±—Ä–∞–∑—Ü–æ–≤
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    mod_mask = df['image'].isin(mod_samples)
    normal_mask = df['image'].isin(normal_samples)
    
    if mod_mask.sum() == 0 or normal_mask.sum() == 0:
        return {
            'score': -np.inf,
            'mean_pc1_mod': -np.inf,
            'mean_pc1_normal': np.inf,
            'separation': -np.inf,
            'explained_variance': 0.0,
        }
    
    # –û–±—É—á–∞–µ–º PCA
    X = df[feature_columns].fillna(0).values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    pca = PCA(n_components=1)
    X_pca = pca.fit_transform(X_scaled)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    pc1_mod = X_pca[mod_mask, 0]
    pc1_normal = X_pca[normal_mask, 0]
    
    mean_pc1_mod = np.mean(pc1_mod)
    mean_pc1_normal = np.mean(pc1_normal)
    separation = mean_pc1_mod - mean_pc1_normal
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º PC1 –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ–∑–∏—Ü–∏–∏ mod –æ–±—Ä–∞–∑—Ü–æ–≤
    pc1_min = X_pca.min()
    pc1_max = X_pca.max()
    if pc1_max > pc1_min:
        pc1_norm_mod = (pc1_mod - pc1_min) / (pc1_max - pc1_min)
        mean_pc1_norm_mod = np.mean(pc1_norm_mod)
    else:
        mean_pc1_norm_mod = 0.5
    
    explained_variance = pca.explained_variance_ratio_[0]
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏ –ø–æ–∑–∏—Ü–∏—é mod –æ–±—Ä–∞–∑—Ü–æ–≤
    score = (
        0.4 * separation +  # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏
        0.3 * mean_pc1_norm_mod +  # –ü–æ–∑–∏—Ü–∏—è mod –æ–±—Ä–∞–∑—Ü–æ–≤ (–±–ª–∏–∂–µ –∫ 1)
        0.3 * explained_variance  # –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
    )
    
    return {
        'score': score,
        'mean_pc1_mod': mean_pc1_mod,
        'mean_pc1_normal': mean_pc1_normal,
        'mean_pc1_norm_mod': mean_pc1_norm_mod,
        'separation': separation,
        'explained_variance': explained_variance,
    }


class FeatureSelector:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    
    def __init__(self, df: pd.DataFrame):
        """
        Args:
            df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –∫–æ–ª–æ–Ω–∫–æ–π 'image'
        """
        self.df = df.copy()
        self.df['sample_type'] = self.df['image'].apply(identify_sample_type)
        
        mod_mask = self.df['sample_type'] == 'mod'
        normal_mask = self.df['sample_type'] == 'normal'
        
        self.mod_samples = self.df[mod_mask]['image'].tolist()
        self.normal_samples = self.df[normal_mask]['image'].tolist()
        
        print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: mod={len(self.mod_samples)}, normal={len(self.normal_samples)}")
    
    def method_1_forward_selection(
        self,
        candidate_features: List[str],
        max_features: Optional[int] = None,
        min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 1: Forward Selection (–∂–∞–¥–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º).
        
        –ù–∞—á–∏–Ω–∞–µ—Ç —Å –ø—É—Å—Ç–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏,
        –∫–æ—Ç–æ—Ä—ã–µ –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É—é—Ç —Ü–µ–ª–µ–≤—É—é –º–µ—Ç—Ä–∏–∫—É.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
            min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        selected = []
        best_score = -np.inf
        best_metrics = {}
        
        remaining = candidate_features.copy()
        
        if max_features is None:
            max_features = len(candidate_features)
        
        print(f"\n=== Forward Selection ===")
        print(f"–ö–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(candidate_features)}")
        
        while len(selected) < max_features and remaining:
            best_feature = None
            best_new_score = best_score
            
            for feature in remaining:
                test_features = selected + [feature]
                metrics = evaluate_feature_set(
                    self.df, test_features, self.mod_samples, self.normal_samples
                )
                
                if metrics['score'] > best_new_score:
                    best_new_score = metrics['score']
                    best_feature = feature
                    best_metrics = metrics
            
            if best_feature is None or (best_new_score - best_score) < min_improvement:
                break
            
            selected.append(best_feature)
            remaining.remove(best_feature)
            best_score = best_new_score
            
            print(f"–®–∞–≥ {len(selected)}: –¥–æ–±–∞–≤–ª–µ–Ω '{best_feature}', score={best_score:.4f}, "
                  f"separation={best_metrics['separation']:.4f}, "
                  f"mod_norm={best_metrics['mean_pc1_norm_mod']:.4f}")
        
        return selected, best_metrics
    
    def method_2_backward_elimination(
        self,
        candidate_features: List[str],
        min_features: int = 1,
        min_improvement: float = 0.01,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 2: Backward Elimination.
        
        –ù–∞—á–∏–Ω–∞–µ—Ç —Å–æ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç –Ω–∞–∏–º–µ–Ω–µ–µ –≤–∞–∂–Ω—ã–µ.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_features: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_improvement: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        selected = candidate_features.copy()
        
        # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        metrics = evaluate_feature_set(
            self.df, selected, self.mod_samples, self.normal_samples
        )
        best_score = metrics['score']
        best_metrics = metrics
        
        print(f"\n=== Backward Elimination ===")
        print(f"–ù–∞—á–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected)}")
        print(f"–ù–∞—á–∞–ª—å–Ω—ã–π score: {best_score:.4f}")
        
        while len(selected) > min_features:
            worst_feature = None
            best_new_score = best_score
            
            for feature in selected:
                test_features = [f for f in selected if f != feature]
                test_metrics = evaluate_feature_set(
                    self.df, test_features, self.mod_samples, self.normal_samples
                )
                
                if test_metrics['score'] > best_new_score:
                    best_new_score = test_metrics['score']
                    worst_feature = feature
            
            if worst_feature is None or (best_new_score - best_score) < min_improvement:
                break
            
            selected.remove(worst_feature)
            best_score = best_new_score
            best_metrics = evaluate_feature_set(
                self.df, selected, self.mod_samples, self.normal_samples
            )
            
            print(f"–®–∞–≥: —É–¥–∞–ª–µ–Ω '{worst_feature}', –æ—Å—Ç–∞–ª–æ—Å—å {len(selected)}, "
                  f"score={best_score:.4f}, "
                  f"separation={best_metrics['separation']:.4f}, "
                  f"mod_norm={best_metrics['mean_pc1_norm_mod']:.4f}")
        
        return selected, best_metrics
    
    def method_3_positive_loadings_filter(
        self,
        candidate_features: List[str],
        min_loading: float = 0.05,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 3: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º loadings PC1.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ loadings –≤ PC1,
        —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –ø–∞—Ç–æ–ª–æ–≥–∏–µ–π.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            min_loading: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π loading –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Positive Loadings Filter ===")
        
        # –û–±—É—á–∞–µ–º PCA –Ω–∞ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        pca = PCA(n_components=1)
        pca.fit(X_scaled)
        
        # –ü–æ–ª—É—á–∞–µ–º loadings
        loadings = pd.Series(pca.components_[0], index=candidate_features)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ loadings
        positive_features = [
            feat for feat, loading in loadings.items()
            if loading > min_loading
        ]
        
        print(f"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö loadings (> {min_loading}): {len(positive_features)} –∏–∑ {len(candidate_features)}")
        
        if not positive_features:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ loadings!")
            positive_features = candidate_features
        
        metrics = evaluate_feature_set(
            self.df, positive_features, self.mod_samples, self.normal_samples
        )
        
        return positive_features, metrics
    
    def method_4_mutual_information(
        self,
        candidate_features: List[str],
        k: Optional[int] = None,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 4: –û—Ç–±–æ—Ä –ø–æ Mutual Information.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∑–∞–∏–º–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            k: –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞ (None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Mutual Information Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –í—ã—á–∏—Å–ª—è–µ–º mutual information
        X = self.df[candidate_features].fillna(0).values
        mi_scores = mutual_info_classif(X, y, random_state=42)
        
        mi_df = pd.DataFrame({
            'feature': candidate_features,
            'mi_score': mi_scores
        }).sort_values('mi_score', ascending=False)
        
        print(f"–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ MI:")
        print(mi_df.head(10).to_string(index=False))
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-k –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if k is None:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å MI > –º–µ–¥–∏–∞–Ω—ã
            threshold = mi_df['mi_score'].median()
            selected_features = mi_df[mi_df['mi_score'] > threshold]['feature'].tolist()
        else:
            selected_features = mi_df.head(k)['feature'].tolist()
        
        print(f"–û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)}")
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_5_lasso_selection(
        self,
        candidate_features: List[str],
        cv: int = 5,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 5: L1-regularization (LASSO) –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LASSO –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            cv: –ß–∏—Å–ª–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== LASSO Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # LASSO —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        lasso = LassoCV(cv=cv, random_state=42, max_iter=2000)
        lasso.fit(X_scaled, y)
        
        # –û—Ç–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
        selected_features = [
            candidate_features[i] for i in range(len(candidate_features))
            if abs(lasso.coef_[i]) > 1e-6
        ]
        
        print(f"LASSO –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {len(candidate_features)}")
        print(f"Alpha (—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è): {lasso.alpha_:.6f}")
        
        if not selected_features:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: LASSO –Ω–µ –≤—ã–±—Ä–∞–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞!")
            selected_features = candidate_features
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_6_rfe_selection(
        self,
        candidate_features: List[str],
        n_features: Optional[int] = None,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 6: Recursive Feature Elimination (RFE).
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç RFE –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            n_features: –ß–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ç–±–æ—Ä–∞ (None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ RFECV)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== RFE Selection ===")
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        y = (self.df['sample_type'] == 'mod').astype(int).values
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = self.df[candidate_features].fillna(0).values
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        estimator = RandomForestClassifier(n_estimators=100, random_state=42)
        
        if n_features is None:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —á–µ—Ä–µ–∑ RFECV
            rfecv = RFECV(estimator=estimator, step=1, cv=5, scoring='roc_auc')
            rfecv.fit(X_scaled, y)
            selected_features = [
                candidate_features[i] for i in range(len(candidate_features))
                if rfecv.support_[i]
            ]
            print(f"RFECV –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        else:
            # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            rfe = RFE(estimator=estimator, n_features_to_select=n_features)
            rfe.fit(X_scaled, y)
            selected_features = [
                candidate_features[i] for i in range(len(candidate_features))
                if rfe.support_[i]
            ]
            print(f"RFE –≤—ã–±—Ä–∞–ª {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        metrics = evaluate_feature_set(
            self.df, selected_features, self.mod_samples, self.normal_samples
        )
        
        return selected_features, metrics
    
    def method_7_brute_force_combinations(
        self,
        candidate_features: List[str],
        max_features: int = 5,
        max_combinations: int = 1000,
    ) -> Tuple[List[str], Dict[str, float]]:
        """
        –ú–µ—Ç–æ–¥ 7: –ü–µ—Ä–µ–±–æ—Ä –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¥–ª—è –º–∞–ª–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤).
        
        –ü–µ—Ä–µ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            max_features: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            max_combinations: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –º–µ—Ç—Ä–∏–∫–∏)
        """
        print(f"\n=== Brute Force Combinations ===")
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º –¥–ª—è –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        best_features = None
        best_score = -np.inf
        best_metrics = {}
        
        total_combinations = sum(
            len(list(combinations(candidate_features, k)))
            for k in range(1, min(max_features + 1, len(candidate_features) + 1))
        )
        
        if total_combinations > max_combinations:
            print(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π ({total_combinations}), –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {max_combinations}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            import random
            combinations_to_test = []
            for k in range(1, min(max_features + 1, len(candidate_features) + 1)):
                for _ in range(max_combinations // max_features):
                    combo = random.sample(candidate_features, min(k, len(candidate_features)))
                    combinations_to_test.append(combo)
        else:
            # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            combinations_to_test = []
            for k in range(1, min(max_features + 1, len(candidate_features) + 1)):
                combinations_to_test.extend(combinations(candidate_features, k))
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º {len(combinations_to_test)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π...")
        
        for i, combo in enumerate(combinations_to_test):
            if i % 100 == 0:
                print(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ {i}/{len(combinations_to_test)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π...")
            
            metrics = evaluate_feature_set(
                self.df, list(combo), self.mod_samples, self.normal_samples
            )
            
            if metrics['score'] > best_score:
                best_score = metrics['score']
                best_features = list(combo)
                best_metrics = metrics
        
        print(f"–õ—É—á—à–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: {len(best_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, score={best_score:.4f}")
        
        return best_features, best_metrics
    
    def compare_all_methods(
        self,
        candidate_features: List[str],
        methods: Optional[List[str]] = None,
    ) -> pd.DataFrame:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        
        Args:
            candidate_features: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (None = –≤—Å–µ –º–µ—Ç–æ–¥—ã)
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if methods is None:
            methods = [
                'forward',
                'backward',
                'positive_loadings',
                'mutual_information',
                'lasso',
                'rfe',
            ]
        
        results = []
        
        for method_name in methods:
            print(f"\n{'='*60}")
            print(f"–ú–µ—Ç–æ–¥: {method_name}")
            print(f"{'='*60}")
            
            try:
                if method_name == 'forward':
                    features, metrics = self.method_1_forward_selection(candidate_features)
                elif method_name == 'backward':
                    features, metrics = self.method_2_backward_elimination(candidate_features)
                elif method_name == 'positive_loadings':
                    features, metrics = self.method_3_positive_loadings_filter(candidate_features)
                elif method_name == 'mutual_information':
                    features, metrics = self.method_4_mutual_information(candidate_features)
                elif method_name == 'lasso':
                    features, metrics = self.method_5_lasso_selection(candidate_features)
                elif method_name == 'rfe':
                    features, metrics = self.method_6_rfe_selection(candidate_features)
                else:
                    continue
                
                results.append({
                    'method': method_name,
                    'n_features': len(features),
                    'features': features,
                    **metrics
                })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç–æ–¥–µ {method_name}: {e}")
                continue
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('score', ascending=False)
        
        return results_df


def run_feature_selection_analysis(
    predictions_dir: Union[str, Path],
    output_dir: Optional[Union[str, Path]] = None,
    methods: Optional[List[str]] = None,
) -> pd.DataFrame:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        predictions_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å JSON —Ñ–∞–π–ª–∞–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (None = –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å)
        methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
    Returns:
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
    """
    print("="*60)
    print("–ê–í–¢–û–ú–ê–¢–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–û–î–ë–û–† –ü–†–ò–ó–ù–ê–ö–û–í –î–õ–Ø –ú–ï–î–ò–¶–ò–ù–°–ö–û–ô –®–ö–ê–õ–´")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = aggregate.load_predictions_batch(predictions_dir)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(df)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n2. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df_features = aggregate.create_relative_features(df)
    print(f"   –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features.columns) - 1}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df_all = aggregate.select_all_feature_columns(df_features)
    candidate_features = [c for c in df_all.columns if c != 'image']
    print(f"   –ö–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(candidate_features)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    print("\n3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    selector = FeatureSelector(df_all)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    print("\n4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    results_df = selector.compare_all_methods(candidate_features, methods=methods)
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "="*60)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø –ú–ï–¢–û–î–û–í")
    print("="*60)
    print(results_df[['method', 'n_features', 'score', 'separation', 
                      'mean_pc1_norm_mod', 'explained_variance']].to_string(index=False))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if output_dir is not None:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print("\n5. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        saved_files = feature_selection_export.export_complete_results(
            results_df=results_df,
            output_dir=output_dir,
            use_relative_features=True,
            auto_export_to_dashboard=False,  # –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            df_aggregated=df,  # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
            df_features=df_features,  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            df_all_features=df_all,  # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        )
        
        print("\n" + "="*60)
        print("–≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù")
        print("="*60)
        print(f"‚úì –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç: {saved_files.get('medical_report', 'N/A')}")
        print(f"‚úì CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {saved_files.get('csv', 'N/A')}")
        print(f"‚úì JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {saved_files.get('json', 'N/A')}")
        if saved_files.get('aggregated_data'):
            print(f"‚úì –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {saved_files.get('aggregated_data', 'N/A')}")
        if saved_files.get('relative_features'):
            print(f"‚úì –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('relative_features', 'N/A')}")
        if saved_files.get('all_features'):
            print(f"‚úì –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('all_features', 'N/A')}")
        print(f"\nüí° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dashboard –ù–ï –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)")
        print(f"   –ß—Ç–æ–±—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ dashboard, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"   python3 -m scale.feature_selection_versioning_cli export {output_dir.name}")
    
    return results_df


if __name__ == "__main__":
    import sys
    
    predictions_dir = sys.argv[1] if len(sys.argv) > 1 else "results/predictions"
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "experiments/feature_selection"
    
    results = run_feature_selection_analysis(predictions_dir, output_dir)

