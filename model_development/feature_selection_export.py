"""
–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è dashboard –∏ –º–µ–¥–∏–∫–æ–≤.

–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
–≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å dashboard, –∏ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è –º–µ–¥–∏–∫–æ–≤.
"""

import json
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import pandas as pd


def export_to_dashboard_config(
    selected_features: List[str],
    output_dir: Path,
    method_name: str,
    metrics: Dict,
    use_relative_features: bool = True,
    description: Optional[str] = None,
) -> Path:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ dashboard.
    
    Args:
        selected_features: –°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –ø–æ–¥–±–æ—Ä–∞
        metrics: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        use_relative_features: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (True) –∏–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ (False)
        description: –û–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if use_relative_features:
        config_filename = "feature_selection_config_relative.json"
    else:
        config_filename = "feature_selection_config_absolute.json"
    
    # –ü—É—Ç—å –¥–ª—è dashboard (–≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ scale/)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ scale/
    project_root = Path(__file__).parent.parent
    dashboard_config_path = project_root / "scale" / config_filename
    
    # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–ø–∏–∏ (–≤ output_dir)
    backup_config_path = output_dir / config_filename
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
    if description is None:
        description = (
            f"–ü—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç–æ–±—Ä–∞–Ω—ã –º–µ—Ç–æ–¥–æ–º '{method_name}'. "
            f"Score: {metrics.get('score', 0):.4f}, "
            f"Separation: {metrics.get('separation', 0):.4f}, "
            f"Mod (–Ω–æ—Ä–º. PC1): {metrics.get('mean_pc1_norm_mod', 0):.4f}, "
            f"–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {metrics.get('explained_variance', 0):.4f}"
        )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = {
        "selected_features": selected_features,
        "description": description,
        "last_updated": datetime.now().isoformat(),
        "method": method_name,
        "metrics": {
            "score": float(metrics.get('score', 0)),
            "separation": float(metrics.get('separation', 0)),
            "mean_pc1_norm_mod": float(metrics.get('mean_pc1_norm_mod', 0)),
            "explained_variance": float(metrics.get('explained_variance', 0)),
            "mean_pc1_mod": float(metrics.get('mean_pc1_mod', 0)),
            "mean_pc1_normal": float(metrics.get('mean_pc1_normal', 0)),
        },
        "n_features": len(selected_features),
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ dashboard –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    with open(dashboard_config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–ø–∏—é –≤ output_dir
    with open(backup_config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"‚úì –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ dashboard: {dashboard_config_path}")
    print(f"‚úì –ö–æ–ø–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {backup_config_path}")
    
    return dashboard_config_path


def create_medical_report(
    results_df: pd.DataFrame,
    output_dir: Path,
    predictions_dir: Optional[Path] = None,
) -> Path:
    """
    –°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –¥–ª—è –º–µ–¥–∏–∫–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞
        predictions_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = output_dir / f"medical_report_{timestamp}.md"
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ score
    results_sorted = results_df.sort_values('score', ascending=False)
    best_result = results_sorted.iloc[0]
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report_lines = [
        "# –û—Ç—á–µ—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —à–∫–∞–ª—ã",
        "",
        f"**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "---",
        "",
        "## –†–µ–∑—é–º–µ",
        "",
        f"**–õ—É—á—à–∏–π –º–µ—Ç–æ–¥:** {best_result['method']}",
        f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {best_result['n_features']}",
        f"**–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (score):** {best_result['score']:.4f}",
        "",
        "### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:",
        f"- **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ (separation):** {best_result['separation']:.4f}",
        f"  - –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏",
        f"- **–ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ mod –æ–±—Ä–∞–∑—Ü–æ–≤ (–Ω–æ—Ä–º. PC1):** {best_result['mean_pc1_norm_mod']:.4f}",
        f"  - –¶–µ–ª—å: –±–ª–∏–∑–∫–æ –∫ 1.0 (–ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—Ä–∞–∑—Ü—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)",
        f"- **–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è PC1:** {best_result['explained_variance']:.4f}",
        f"  - –î–æ–ª—è –≤–∞—Ä–∏–∞—Ü–∏–∏, –æ–±—ä—è—Å–Ω—è–µ–º–∞—è –ø–µ—Ä–≤–æ–π –≥–ª–∞–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–π",
        "",
        "---",
        "",
        "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤",
        "",
        "| –ú–µ—Ç–æ–¥ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | Score | Separation | Mod (–Ω–æ—Ä–º.) | –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è |",
        "|-------|---------------------|-------|------------|-------------|----------------------|",
    ]
    
    for _, row in results_sorted.iterrows():
        report_lines.append(
            f"| {row['method']} | {row['n_features']} | {row['score']:.4f} | "
            f"{row['separation']:.4f} | {row['mean_pc1_norm_mod']:.4f} | "
            f"{row['explained_variance']:.4f} |"
        )
    
    report_lines.extend([
        "",
        "---",
        "",
        "## –û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ª—É—á—à–∏–π –º–µ—Ç–æ–¥)",
        "",
        f"**–ú–µ—Ç–æ–¥:** {best_result['method']}",
        f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {best_result['n_features']}",
        "",
        "### –°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:",
        "",
    ])
    
    features = best_result['features']
    for i, feat in enumerate(features, 1):
        report_lines.append(f"{i:2d}. {feat}")
    
    report_lines.extend([
        "",
        "---",
        "",
        "## –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
        "",
        "### –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–∞–∂–¥–∞—è –º–µ—Ç—Ä–∏–∫–∞:",
        "",
        "1. **Score (–∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞):**",
        "   - –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞, —É—á–∏—Ç—ã–≤–∞—é—â–∞—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø, –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–Ω—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é",
        "   - –ß–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ",
        "",
        "2. **Separation (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ):**",
        "   - –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Å—Ä–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ PC1 –¥–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö (mod) –∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤",
        "   - –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—Ä–∞–∑—Ü—ã –∏–º–µ—é—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è PC1",
        "   - –¶–µ–ª—å: > 2.0",
        "",
        "3. **Mod (–Ω–æ—Ä–º. PC1):**",
        "   - –°—Ä–µ–¥–Ω–µ–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ PC1 –¥–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ (—à–∫–∞–ª–∞ 0-1)",
        "   - –ó–Ω–∞—á–µ–Ω–∏–µ 0.0 –æ–∑–Ω–∞—á–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ PC1, 1.0 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ",
        "   - –¶–µ–ª—å: > 0.7 (–±–ª–∏–∂–µ –∫ 1.0)",
        "",
        "4. **–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è:**",
        "   - –î–æ–ª—è –æ–±—â–µ–π –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–±—ä—è—Å–Ω—è–µ–º–∞—è –ø–µ—Ä–≤–æ–π –≥–ª–∞–≤–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–π (PC1)",
        "   - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ PC1 –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –æ–±—Ä–∞–∑—Ü–∞–º–∏",
        "   - –¶–µ–ª—å: > 0.3 (30%)",
        "",
        "---",
        "",
        "## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
        "",
    ])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
    if best_result['mean_pc1_norm_mod'] < 0.7:
        report_lines.append(
            "‚ö†Ô∏è **–ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å** "
            f"(—Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {best_result['mean_pc1_norm_mod']:.4f}, —Ü–µ–ª—å: > 0.7)"
        )
        report_lines.append("")
    
    if best_result['separation'] < 2.0:
        report_lines.append(
            "‚ö†Ô∏è **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å** "
            f"(—Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {best_result['separation']:.4f}, —Ü–µ–ª—å: > 2.0)"
        )
        report_lines.append("")
    
    if best_result['explained_variance'] < 0.3:
        report_lines.append(
            "‚ö†Ô∏è **–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å** "
            f"(—Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {best_result['explained_variance']:.4f}, —Ü–µ–ª—å: > 0.3)"
        )
        report_lines.append("")
    
    if best_result['mean_pc1_norm_mod'] >= 0.7 and best_result['separation'] >= 2.0:
        report_lines.append("‚úÖ **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ü–µ–ª–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º!**")
        report_lines.append("")
    
    report_lines.extend([
        "---",
        "",
        "## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
        "",
        "### –í dashboard:",
        "",
        "1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª:",
        f"   - `scale/feature_selection_config_relative.json` (–¥–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)",
        "",
        "2. –ü—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ dashboard —ç—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã",
        "",
        "3. –í—ã –º–æ–∂–µ—Ç–µ –≤—Ä—É—á–Ω—É—é –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ dashboard —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å",
        "",
        "### –î–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
        "",
        "1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è PCA —à–∫–∞–ª—ã",
        "2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ dashboard",
        "3. –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö",
        "",
        "---",
        "",
        f"*–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤*",
    ])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_content = "\n".join(report_lines)
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"‚úì –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    return report_path


def export_complete_results(
    results_df: pd.DataFrame,
    output_dir: Path,
    use_relative_features: bool = True,
    auto_export_to_dashboard: bool = False,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    df_aggregated: Optional[pd.DataFrame] = None,  # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
    df_features: Optional[pd.DataFrame] = None,  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_all_features: Optional[pd.DataFrame] = None,  # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
) -> Dict[str, Path]:
    """
    –ü–æ–ª–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    
    Args:
        results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        use_relative_features: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        auto_export_to_dashboard: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ dashboard
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    saved_files = {}
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_sorted = results_df.sort_values('score', ascending=False)
    best_result = results_sorted.iloc[0]
    
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    csv_path = output_dir / f"feature_selection_results_{timestamp}.csv"
    results_df.to_csv(csv_path, index=False)
    saved_files['csv'] = csv_path
    print(f"‚úì CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {csv_path}")
    
    # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å –ª—É—á—à–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    json_path = output_dir / f"best_features_{timestamp}.json"
    best_config = {
        'method': best_result['method'],
        'selected_features': best_result['features'],
        'metrics': {
            'score': float(best_result['score']),
            'separation': float(best_result['separation']),
            'mean_pc1_norm_mod': float(best_result['mean_pc1_norm_mod']),
            'explained_variance': float(best_result['explained_variance']),
            'mean_pc1_mod': float(best_result['mean_pc1_mod']),
            'mean_pc1_normal': float(best_result['mean_pc1_normal']),
        },
        'timestamp': timestamp,
    }
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(best_config, f, indent=2, ensure_ascii=False)
    saved_files['json'] = json_path
    print(f"‚úì JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {json_path}")
    
    # 3. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ dashboard –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω–æ)
    if auto_export_to_dashboard:
        dashboard_config_path = export_to_dashboard_config(
            selected_features=best_result['features'],
            output_dir=output_dir,
            method_name=best_result['method'],
            metrics=best_result.to_dict(),
            use_relative_features=use_relative_features,
        )
        saved_files['dashboard_config'] = dashboard_config_path
        print(f"\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dashboard –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
        print(f"   –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"   python3 -m scale.feature_selection_versioning export <experiment_name>")
    else:
        print(f"\nüí° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dashboard –ù–ï –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)")
        print(f"   –ß—Ç–æ–±—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ dashboard, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"   python3 -m scale.feature_selection_versioning export {output_dir.name}")
    
    # 4. –°–æ–∑–¥–∞–µ–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç
    report_path = create_medical_report(
        results_df=results_df,
        output_dir=output_dir,
    )
    saved_files['medical_report'] = report_path
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã)
    if df_aggregated is not None:
        aggregated_path = output_dir / f"aggregated_data_{timestamp}.csv"
        df_aggregated.to_csv(aggregated_path, index=False)
        saved_files['aggregated_data'] = aggregated_path
        print(f"‚úì –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {aggregated_path}")
    
    if df_features is not None:
        features_path = output_dir / f"relative_features_{timestamp}.csv"
        df_features.to_csv(features_path, index=False)
        saved_files['relative_features'] = features_path
        print(f"‚úì –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {features_path}")
    
    if df_all_features is not None:
        all_features_path = output_dir / f"all_features_{timestamp}.csv"
        df_all_features.to_csv(all_features_path, index=False)
        saved_files['all_features'] = all_features_path
        print(f"‚úì –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {all_features_path}")
    
    return saved_files


def export_to_experiment_format(
    selected_features: List[str],
    output_dir: Path,
    method_name: str,
    metrics: Dict,
    df_results: Optional[pd.DataFrame] = None,
    analyzer: Optional[object] = None,
    use_relative_features: bool = True,
    metadata: Optional[Dict] = None,
) -> Path:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç experiments –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ dashboard.
    
    –§–æ—Ä–º–∞—Ç experiments –≤–∫–ª—é—á–∞–µ—Ç:
    - results.csv - DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    - spectral_analyzer.pkl - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞)
    - metadata.json - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    - best_features_*.json - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    
    Args:
        selected_features: –°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        method_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –ø–æ–¥–±–æ—Ä–∞
        metrics: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        df_results: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        analyzer: –û–±—É—á–µ–Ω–Ω—ã–π SpectralAnalyzer (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        use_relative_features: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ best_features_*.json
    json_path = output_dir / f"best_features_{timestamp}.json"
    config = {
        'method': method_name,
        'selected_features': selected_features,
        'metrics': {
            'score': float(metrics.get('score', 0)),
            'separation': float(metrics.get('separation', 0)),
            'mean_pc1_norm_mod': float(metrics.get('mean_pc1_norm_mod', 0)),
            'explained_variance': float(metrics.get('explained_variance', 0)),
            'mean_pc1_mod': float(metrics.get('mean_pc1_mod', 0)),
            'mean_pc1_normal': float(metrics.get('mean_pc1_normal', 0)),
        },
        'timestamp': timestamp,
        'use_relative_features': use_relative_features,
    }
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    print(f"‚úì –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {json_path}")
    
    # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã)
    if df_results is not None:
        csv_path = output_dir / "results.csv"
        df_results.to_csv(csv_path, index=False)
        print(f"‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {csv_path}")
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å (–µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∞)
    if analyzer is not None:
        model_path = output_dir / "spectral_analyzer.pkl"
        analyzer.save(model_path)
        print(f"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    if metadata is None:
        metadata = {}
    
    metadata.update({
        "timestamp": datetime.now().isoformat(),
        "method": method_name,
        "n_features": len(selected_features),
        "use_relative_features": use_relative_features,
        "metrics": config['metrics'],
    })
    
    if df_results is not None:
        metadata["n_samples"] = len(df_results)
    
    metadata_path = output_dir / "metadata.json"
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print(f"‚úì –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
    
    print(f"\n‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ experiments: {output_dir}")
    
    return output_dir

