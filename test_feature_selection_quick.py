#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–µ—Ç–æ–¥–æ–≤ –ø–æ–¥–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏–Ω—Ç—É–∏—Ü–∏–∏ –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
"""

import sys
from pathlib import Path
import pandas as pd

from scale import aggregate
from scale.feature_selection_automated import FeatureSelector
from scale import feature_selection_export

def main():
    print("="*70)
    print("–ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ú–ï–¢–û–î–û–í –ü–û–î–ë–û–†–ê –ü–†–ò–ó–ù–ê–ö–û–í")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    predictions_dir = sys.argv[1] if len(sys.argv) > 1 else "results/predictions"
    df = aggregate.load_predictions_batch(predictions_dir)
    print(f"   ‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(df)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n2. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df_features = aggregate.create_relative_features(df)
    print(f"   ‚úì –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features.columns) - 1}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df_all = aggregate.select_all_feature_columns(df_features)
    candidate_features = [c for c in df_all.columns if c != 'image']
    print(f"   ‚úì –ö–∞–Ω–¥–∏–¥–∞—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(candidate_features)}")
    print(f"   –ü—Ä–∏–º–µ—Ä—ã: {candidate_features[:5]}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    print("\n4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–ª–µ–∫—Ç–æ—Ä–∞...")
    selector = FeatureSelector(df_all)
    print(f"   ‚úì Mod –æ–±—Ä–∞–∑—Ü–æ–≤: {len(selector.mod_samples)}")
    print(f"   ‚úì Normal –æ–±—Ä–∞–∑—Ü–æ–≤: {len(selector.normal_samples)}")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
    print("\n" + "="*70)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–ï–¢–û–î–û–í")
    print("="*70)
    
    results = []
    
    # –ú–µ—Ç–æ–¥ 1: Positive Loadings Filter (–±—ã—Å—Ç—Ä—ã–π)
    print("\n[1/4] Positive Loadings Filter...")
    try:
        features, metrics = selector.method_3_positive_loadings_filter(
            candidate_features,
            min_loading=0.05
        )
        results.append({
            'method': 'positive_loadings',
            'n_features': len(features),
            'features': features,
            **metrics
        })
        print(f"   ‚úì –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features)}")
        print(f"   ‚úì Score: {metrics['score']:.4f}")
        print(f"   ‚úì Separation: {metrics['separation']:.4f}")
        print(f"   ‚úì Mod (–Ω–æ—Ä–º.): {metrics['mean_pc1_norm_mod']:.4f}")
    except Exception as e:
        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
    
    # –ú–µ—Ç–æ–¥ 2: Forward Selection (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π)
    print("\n[2/4] Forward Selection (–¥–æ 15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)...")
    try:
        features, metrics = selector.method_1_forward_selection(
            candidate_features,
            max_features=15,
            min_improvement=0.005
        )
        results.append({
            'method': 'forward_selection',
            'n_features': len(features),
            'features': features,
            **metrics
        })
        print(f"   ‚úì –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features)}")
        print(f"   ‚úì Score: {metrics['score']:.4f}")
        print(f"   ‚úì Separation: {metrics['separation']:.4f}")
        print(f"   ‚úì Mod (–Ω–æ—Ä–º.): {metrics['mean_pc1_norm_mod']:.4f}")
        print(f"   ‚úì –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {metrics['explained_variance']:.4f}")
    except Exception as e:
        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
    
    # –ú–µ—Ç–æ–¥ 3: Mutual Information
    print("\n[3/4] Mutual Information...")
    try:
        features, metrics = selector.method_4_mutual_information(
            candidate_features,
            k=None  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
        )
        results.append({
            'method': 'mutual_information',
            'n_features': len(features),
            'features': features,
            **metrics
        })
        print(f"   ‚úì –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features)}")
        print(f"   ‚úì Score: {metrics['score']:.4f}")
        print(f"   ‚úì Separation: {metrics['separation']:.4f}")
        print(f"   ‚úì Mod (–Ω–æ—Ä–º.): {metrics['mean_pc1_norm_mod']:.4f}")
    except Exception as e:
        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
    
    # –ú–µ—Ç–æ–¥ 4: LASSO
    print("\n[4/4] LASSO Selection...")
    try:
        features, metrics = selector.method_5_lasso_selection(
            candidate_features,
            cv=3  # –£–º–µ–Ω—å—à–∞–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        )
        results.append({
            'method': 'lasso',
            'n_features': len(features),
            'features': features,
            **metrics
        })
        print(f"   ‚úì –û—Ç–æ–±—Ä–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features)}")
        print(f"   ‚úì Score: {metrics['score']:.4f}")
        print(f"   ‚úì Separation: {metrics['separation']:.4f}")
        print(f"   ‚úì Mod (–Ω–æ—Ä–º.): {metrics['mean_pc1_norm_mod']:.4f}")
    except Exception as e:
        print(f"   ‚úó –û—à–∏–±–∫–∞: {e}")
    
    # –í—ã–≤–æ–¥ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    print("\n" + "="*70)
    print("–°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*70)
    
    if results:
        import pandas as pd
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('score', ascending=False)
        
        print("\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
        print("-" * 70)
        for idx, row in results_df.iterrows():
            print(f"\n{row['method']}:")
            print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {row['n_features']}")
            print(f"  Score:                {row['score']:.4f}")
            print(f"  Separation:           {row['separation']:.4f}")
            print(f"  Mod (–Ω–æ—Ä–º. PC1):      {row['mean_pc1_norm_mod']:.4f}")
            print(f"  –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {row['explained_variance']:.4f}")
            print(f"  Mean PC1 (mod):       {row['mean_pc1_mod']:.4f}")
            print(f"  Mean PC1 (normal):    {row['mean_pc1_normal']:.4f}")
        
        print("\n" + "="*70)
        print("–õ–£–ß–®–ò–ô –ú–ï–¢–û–î (–ø–æ score):")
        print("="*70)
        best = results_df.iloc[0]
        print(f"\n–ú–µ—Ç–æ–¥: {best['method']}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {best['n_features']}")
        print(f"\n–û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
        for i, feat in enumerate(best['features'], 1):
            print(f"  {i:2d}. {feat}")
        
        print(f"\n–ú–µ—Ç—Ä–∏–∫–∏:")
        print(f"  Score:                {best['score']:.4f}")
        print(f"  Separation:           {best['separation']:.4f}")
        print(f"  Mod (–Ω–æ—Ä–º. PC1):      {best['mean_pc1_norm_mod']:.4f}")
        print(f"  –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {best['explained_variance']:.4f}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("\n" + "="*70)
        print("–ê–ù–ê–õ–ò–ó –û–¢–û–ë–†–ê–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
        print("="*70)
        
        # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        from collections import Counter
        all_features = []
        for r in results:
            all_features.extend(r['features'])
        
        feature_counts = Counter(all_features)
        print("\n–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—è–≤–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö:")
        for feat, count in feature_counts.most_common():
            print(f"  {count:2d}x {feat}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n" + "="*70)
        print("–≠–ö–°–ü–û–†–¢ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*70)
        
        results_df = pd.DataFrame(results)
        output_dir = Path("experiments/feature_selection_quick")
        
        try:
            saved_files = feature_selection_export.export_complete_results(
                results_df=results_df,
                output_dir=output_dir,
                use_relative_features=True,
                auto_export_to_dashboard=False,  # –ù–ï —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                df_aggregated=df,  # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                df_features=df_features,  # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                df_all_features=df_all,  # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            )
            
            print("\n‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã:")
            print(f"  - –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç: {saved_files.get('medical_report', 'N/A')}")
            print(f"  - CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {saved_files.get('csv', 'N/A')}")
            print(f"  - JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {saved_files.get('json', 'N/A')}")
            if saved_files.get('aggregated_data'):
                print(f"  - –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {saved_files.get('aggregated_data', 'N/A')}")
            if saved_files.get('relative_features'):
                print(f"  - –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('relative_features', 'N/A')}")
            if saved_files.get('all_features'):
                print(f"  - –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {saved_files.get('all_features', 'N/A')}")
            print(f"\nüí° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è dashboard –ù–ï –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (–¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)")
            print(f"   –ß—Ç–æ–±—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ dashboard, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
            print(f"   python3 -m scale.feature_selection_versioning_cli export {output_dir.name}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {e}")
        
    else:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∏ –æ—Ç –æ–¥–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞.")
    
    print("\n" + "="*70)

if __name__ == "__main__":
    main()

